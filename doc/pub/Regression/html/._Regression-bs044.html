<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="description" content="Data Analysis and Machine Learning: Linear Regression and more Advanced Regression Analysis">

<title>Data Analysis and Machine Learning: Linear Regression and more Advanced Regression Analysis</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Regression analysis, overarching aims', 2, None, '___sec0'),
              ('Regression analysis, overarching aims II', 2, None, '___sec1'),
              ('General linear models', 2, None, '___sec2'),
              ('Rewriting the fitting procedure as a linear algebra problem',
               2,
               None,
               '___sec3'),
              ('Rewriting the fitting procedure as a linear algebra problem, '
               'follows',
               2,
               None,
               '___sec4'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               '___sec5'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               '___sec6'),
              ('Optimizing our parameters', 2, None, '___sec7'),
              ('Optimizing our parameters, more details', 2, None, '___sec8'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               '___sec9'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               '___sec10'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               '___sec11'),
              ('The $\\chi^2$ function', 2, None, '___sec12'),
              ('The $\\chi^2$ function', 2, None, '___sec13'),
              ('The $\\chi^2$ function', 2, None, '___sec14'),
              ('The $\\chi^2$ function', 2, None, '___sec15'),
              ('The $\\chi^2$ function', 2, None, '___sec16'),
              ('The $\\chi^2$ function', 2, None, '___sec17'),
              ('Simple regression model', 2, None, '___sec18'),
              ('Simple regression model, now using _scikit-learn_',
               2,
               None,
               '___sec19'),
              ('Simple linear regression model using _scikit-learn_',
               2,
               None,
               '___sec20'),
              ('Simple linear regression model', 2, None, '___sec21'),
              ('Less noise', 2, None, '___sec22'),
              ('How to study our fits', 2, None, '___sec23'),
              ('Minimizing the cost function', 2, None, '___sec24'),
              ('Relative error', 2, None, '___sec25'),
              ('The richness of _scikit-learn_', 2, None, '___sec26'),
              ('Functions in _scikit-learn_', 2, None, '___sec27'),
              ('Other functions in  _scikit-learn_', 2, None, '___sec28'),
              ('The mean absolute error and other functions in  _scikit-learn_',
               2,
               None,
               '___sec29'),
              ('Cubic polynomial in  _scikit-learn_', 2, None, '___sec30'),
              ('Polynomial Regression', 2, None, '___sec31'),
              ('Linking the regression analysis with a statistical '
               'interpretation',
               2,
               None,
               '___sec32'),
              ('Expectation value and variance', 2, None, '___sec33'),
              ('The singular value decompostion', 2, None, '___sec34'),
              ('From standard regression to Ridge regressions',
               2,
               None,
               '___sec35'),
              ('Fixing the singularity', 2, None, '___sec36'),
              ('Fitting vs. predicting when data is in the model class',
               2,
               None,
               '___sec37'),
              ('Fitting versus predicting when data is not in the model class',
               2,
               None,
               '___sec38'),
              ('An example code without the model assessment part',
               2,
               None,
               '___sec39'),
              ('Generating test data', 2, None, '___sec40'),
              ('How can we effectively evaluate the various models?',
               2,
               None,
               '___sec41'),
              ('Code examples for Ridge and Lasso Regression',
               2,
               None,
               '___sec42'),
              ('A second-order polynomial with Ridge and Lasso',
               2,
               None,
               '___sec43'),
              ('Resampling methods', 2, None, '___sec44'),
              ('Resampling approaches can be computationally expensive',
               2,
               None,
               '___sec45'),
              ('Log-likelihood', 2, None, '___sec46'),
              ('Cross-validation', 2, None, '___sec47'),
              ('Computationally expensive', 2, None, '___sec48'),
              ('Various steps in cross-validation', 2, None, '___sec49'),
              ('How to set up the cross-validation for Ridge and/or Lasso',
               2,
               None,
               '___sec50'),
              ('Predicted Residual Error Sum of Squares', 2, None, '___sec51'),
              ('Bootstrap', 2, None, '___sec52')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="Regression-bs.html">Data Analysis and Machine Learning: Linear Regression and more Advanced Regression Analysis</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._Regression-bs001.html#___sec0" style="font-size: 80%;">Regression analysis, overarching aims</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs002.html#___sec1" style="font-size: 80%;">Regression analysis, overarching aims II</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs003.html#___sec2" style="font-size: 80%;">General linear models</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs004.html#___sec3" style="font-size: 80%;">Rewriting the fitting procedure as a linear algebra problem</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs005.html#___sec4" style="font-size: 80%;">Rewriting the fitting procedure as a linear algebra problem, follows</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs006.html#___sec5" style="font-size: 80%;">Generalizing the fitting procedure as a linear algebra problem</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs007.html#___sec6" style="font-size: 80%;">Generalizing the fitting procedure as a linear algebra problem</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs008.html#___sec7" style="font-size: 80%;">Optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs009.html#___sec8" style="font-size: 80%;">Optimizing our parameters, more details</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs010.html#___sec9" style="font-size: 80%;">Interpretations and optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs011.html#___sec10" style="font-size: 80%;">Interpretations and optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs012.html#___sec11" style="font-size: 80%;">Interpretations and optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs013.html#___sec12" style="font-size: 80%;">The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs014.html#___sec13" style="font-size: 80%;">The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs015.html#___sec14" style="font-size: 80%;">The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs016.html#___sec15" style="font-size: 80%;">The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs017.html#___sec16" style="font-size: 80%;">The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs018.html#___sec17" style="font-size: 80%;">The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs019.html#___sec18" style="font-size: 80%;">Simple regression model</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs020.html#___sec19" style="font-size: 80%;">Simple regression model, now using <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs021.html#___sec20" style="font-size: 80%;">Simple linear regression model using <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs022.html#___sec21" style="font-size: 80%;">Simple linear regression model</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs023.html#___sec22" style="font-size: 80%;">Less noise</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs024.html#___sec23" style="font-size: 80%;">How to study our fits</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs025.html#___sec24" style="font-size: 80%;">Minimizing the cost function</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs026.html#___sec25" style="font-size: 80%;">Relative error</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs027.html#___sec26" style="font-size: 80%;">The richness of <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs028.html#___sec27" style="font-size: 80%;">Functions in <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs029.html#___sec28" style="font-size: 80%;">Other functions in  <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs030.html#___sec29" style="font-size: 80%;">The mean absolute error and other functions in  <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs031.html#___sec30" style="font-size: 80%;">Cubic polynomial in  <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs032.html#___sec31" style="font-size: 80%;">Polynomial Regression</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs033.html#___sec32" style="font-size: 80%;">Linking the regression analysis with a statistical interpretation</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs034.html#___sec33" style="font-size: 80%;">Expectation value and variance</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs035.html#___sec34" style="font-size: 80%;">The singular value decompostion</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs036.html#___sec35" style="font-size: 80%;">From standard regression to Ridge regressions</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs037.html#___sec36" style="font-size: 80%;">Fixing the singularity</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs038.html#___sec37" style="font-size: 80%;">Fitting vs. predicting when data is in the model class</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs039.html#___sec38" style="font-size: 80%;">Fitting versus predicting when data is not in the model class</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs040.html#___sec39" style="font-size: 80%;">An example code without the model assessment part</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs041.html#___sec40" style="font-size: 80%;">Generating test data</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs042.html#___sec41" style="font-size: 80%;">How can we effectively evaluate the various models?</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs043.html#___sec42" style="font-size: 80%;">Code examples for Ridge and Lasso Regression</a></li>
     <!-- navigation toc: --> <li><a href="#___sec43" style="font-size: 80%;">A second-order polynomial with Ridge and Lasso</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs045.html#___sec44" style="font-size: 80%;">Resampling methods</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs046.html#___sec45" style="font-size: 80%;">Resampling approaches can be computationally expensive</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs047.html#___sec46" style="font-size: 80%;">Log-likelihood</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs048.html#___sec47" style="font-size: 80%;">Cross-validation</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs049.html#___sec48" style="font-size: 80%;">Computationally expensive</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs050.html#___sec49" style="font-size: 80%;">Various steps in cross-validation</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs051.html#___sec50" style="font-size: 80%;">How to set up the cross-validation for Ridge and/or Lasso</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs052.html#___sec51" style="font-size: 80%;">Predicted Residual Error Sum of Squares</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs053.html#___sec52" style="font-size: 80%;">Bootstrap</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0044"></a>
<!-- !split -->

<h2 id="___sec43" class="anchor">A second-order polynomial with Ridge and Lasso </h2>
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.linear_model</span> <span style="color: #008000; font-weight: bold">import</span> Ridge
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.metrics</span> <span style="color: #008000; font-weight: bold">import</span> r2_score

np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>seed(<span style="color: #666666">4155</span>)

n_samples <span style="color: #666666">=</span> <span style="color: #666666">100</span>

x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>rand(n_samples,<span style="color: #666666">1</span>)
y <span style="color: #666666">=</span> <span style="color: #666666">5*</span>x<span style="color: #666666">*</span>x <span style="color: #666666">+</span> <span style="color: #666666">0.1*</span>np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>rand(n_samples,<span style="color: #666666">1</span>)

<span style="color: #408080; font-style: italic"># Centering  x and y.</span>
x_ <span style="color: #666666">=</span> x <span style="color: #666666">-</span> np<span style="color: #666666">.</span>mean(x)
y_ <span style="color: #666666">=</span> y <span style="color: #666666">-</span> np<span style="color: #666666">.</span>mean(y) <span style="color: #408080; font-style: italic"># beta_0 = mean(y)</span>

X <span style="color: #666666">=</span> np<span style="color: #666666">.</span>c_[np<span style="color: #666666">.</span>ones((n_samples,<span style="color: #666666">1</span>)), x, x<span style="color: #666666">**2</span>]
X_ <span style="color: #666666">=</span> np<span style="color: #666666">.</span>c_[x_, x_<span style="color: #666666">**2</span>]


<span style="color: #408080; font-style: italic">### 1.</span>
lmb_values <span style="color: #666666">=</span> [<span style="color: #666666">1e-4</span>, <span style="color: #666666">1e-3</span>, <span style="color: #666666">1e-2</span>, <span style="color: #666666">10</span>, <span style="color: #666666">1e2</span>, <span style="color: #666666">1e4</span>]
num_values <span style="color: #666666">=</span> <span style="color: #008000">len</span>(lmb_values)

<span style="color: #408080; font-style: italic">## Ridge-regression of centered and not centered data</span>
beta_ridge <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #666666">3</span>,num_values))
beta_ridge_centered <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #666666">3</span>,num_values))

I3 <span style="color: #666666">=</span> np<span style="color: #666666">.</span>eye(<span style="color: #666666">3</span>)
I2 <span style="color: #666666">=</span> np<span style="color: #666666">.</span>eye(<span style="color: #666666">2</span>)

<span style="color: #008000; font-weight: bold">for</span> i,lmb <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(lmb_values):
    beta_ridge[:,i] <span style="color: #666666">=</span> (np<span style="color: #666666">.</span>linalg<span style="color: #666666">.</span>inv( X<span style="color: #666666">.</span>T @ X <span style="color: #666666">+</span> lmb<span style="color: #666666">*</span>I3) @ X<span style="color: #666666">.</span>T @ y)<span style="color: #666666">.</span>flatten()
    beta_ridge_centered[<span style="color: #666666">1</span>:,i] <span style="color: #666666">=</span> (np<span style="color: #666666">.</span>linalg<span style="color: #666666">.</span>inv( X_<span style="color: #666666">.</span>T @ X_ <span style="color: #666666">+</span> lmb<span style="color: #666666">*</span>I2) @ X_<span style="color: #666666">.</span>T @ y_)<span style="color: #666666">.</span>flatten()

<span style="color: #408080; font-style: italic"># sett beta_0 = np.mean(y)</span>
beta_ridge_centered[<span style="color: #666666">0</span>,:] <span style="color: #666666">=</span> np<span style="color: #666666">.</span>mean(y)

<span style="color: #408080; font-style: italic">## OLS (ordinary least squares) solution </span>
beta_ls <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linalg<span style="color: #666666">.</span>inv( X<span style="color: #666666">.</span>T @ X ) @ X<span style="color: #666666">.</span>T @ y

<span style="color: #408080; font-style: italic">## Evaluate the models</span>
pred_ls <span style="color: #666666">=</span> X @ beta_ls
pred_ridge <span style="color: #666666">=</span>  X @ beta_ridge
pred_ridge_centered <span style="color: #666666">=</span>  X_ @ beta_ridge_centered[<span style="color: #666666">1</span>:] <span style="color: #666666">+</span> beta_ridge_centered[<span style="color: #666666">0</span>,:]

<span style="color: #408080; font-style: italic">## Plot the results</span>

<span style="color: #408080; font-style: italic"># Sorting</span>
sort_ind <span style="color: #666666">=</span> np<span style="color: #666666">.</span>argsort(x[:,<span style="color: #666666">0</span>])

x_plot <span style="color: #666666">=</span> x[sort_ind,<span style="color: #666666">0</span>]
x_centered_plot <span style="color: #666666">=</span> x_[sort_ind,<span style="color: #666666">0</span>]

pred_ls_plot <span style="color: #666666">=</span> pred_ls[sort_ind,<span style="color: #666666">0</span>]
pred_ridge_plot <span style="color: #666666">=</span> pred_ridge[sort_ind,:]
pred_ridge_centered_plot <span style="color: #666666">=</span> pred_ridge_centered[sort_ind,:]

<span style="color: #408080; font-style: italic"># Plott not centered</span>
plt<span style="color: #666666">.</span>plot(x_plot,pred_ls_plot,label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;ls&#39;</span>)

<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(num_values):
    plt<span style="color: #666666">.</span>plot(x_plot,pred_ridge_plot[:,i],label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;ridge, lmb=</span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>lmb_values[i])

plt<span style="color: #666666">.</span>plot(x,y,<span style="color: #BA2121">&#39;ro&#39;</span>)

plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;linear regression on un-centered data&#39;</span>)
plt<span style="color: #666666">.</span>legend()

<span style="color: #408080; font-style: italic"># Plott centered</span>
plt<span style="color: #666666">.</span>figure()

<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(num_values):
    plt<span style="color: #666666">.</span>plot(x_centered_plot,pred_ridge_centered_plot[:,i],label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;ridge, lmb=</span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>lmb_values[i])

plt<span style="color: #666666">.</span>plot(x_,y,<span style="color: #BA2121">&#39;ro&#39;</span>)

plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;linear regression on centered data&#39;</span>)
plt<span style="color: #666666">.</span>legend()


<span style="color: #408080; font-style: italic"># 2.</span>

pred_ridge_scikit <span style="color: #666666">=</span>  np<span style="color: #666666">.</span>zeros((n_samples,num_values))
<span style="color: #008000; font-weight: bold">for</span> i,lmb <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(lmb_values):
    pred_ridge_scikit[:,i] <span style="color: #666666">=</span> (Ridge(alpha<span style="color: #666666">=</span>lmb,fit_intercept<span style="color: #666666">=</span><span style="color: #008000">False</span>)<span style="color: #666666">.</span>fit(X,y)<span style="color: #666666">.</span>predict(X))<span style="color: #666666">.</span>flatten() <span style="color: #408080; font-style: italic"># fit_intercept=False fordi bias er allerede i X</span>

plt<span style="color: #666666">.</span>figure()

plt<span style="color: #666666">.</span>plot(x_plot,pred_ls_plot,label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;ls&#39;</span>)

<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(num_values):
    plt<span style="color: #666666">.</span>plot(x_plot,pred_ridge_scikit[sort_ind,i],label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;scikit-ridge, lmb=</span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>lmb_values[i])

plt<span style="color: #666666">.</span>plot(x,y,<span style="color: #BA2121">&#39;ro&#39;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&#39;linear regression using scikit&#39;</span>)

plt<span style="color: #666666">.</span>show()

<span style="color: #408080; font-style: italic">### R2-score of the results</span>
<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(num_values):
    <span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;lambda = </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>lmb_values[i])
    <span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;r2 for scikit: </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>r2_score(y,pred_ridge_scikit[:,i]))
    <span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;r2 for own code, not centered: </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>r2_score(y,pred_ridge[:,i]))
    <span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;r2 for own, centered: </span><span style="color: #BB6688; font-weight: bold">%g</span><span style="color: #BB6622; font-weight: bold">\n</span><span style="color: #BA2121">&#39;</span><span style="color: #666666">%</span>r2_score(y,pred_ridge_centered[:,i]))
</pre></div>
<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._Regression-bs043.html">&laquo;</a></li>
  <li><a href="._Regression-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._Regression-bs036.html">37</a></li>
  <li><a href="._Regression-bs037.html">38</a></li>
  <li><a href="._Regression-bs038.html">39</a></li>
  <li><a href="._Regression-bs039.html">40</a></li>
  <li><a href="._Regression-bs040.html">41</a></li>
  <li><a href="._Regression-bs041.html">42</a></li>
  <li><a href="._Regression-bs042.html">43</a></li>
  <li><a href="._Regression-bs043.html">44</a></li>
  <li class="active"><a href="._Regression-bs044.html">45</a></li>
  <li><a href="._Regression-bs045.html">46</a></li>
  <li><a href="._Regression-bs046.html">47</a></li>
  <li><a href="._Regression-bs047.html">48</a></li>
  <li><a href="._Regression-bs048.html">49</a></li>
  <li><a href="._Regression-bs049.html">50</a></li>
  <li><a href="._Regression-bs050.html">51</a></li>
  <li><a href="._Regression-bs051.html">52</a></li>
  <li><a href="._Regression-bs052.html">53</a></li>
  <li><a href="._Regression-bs053.html">54</a></li>
  <li><a href="._Regression-bs045.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

