<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Data Analysis and Machine Learning: Linear Regression and more Advanced Regression Analysis">

<title>Data Analysis and Machine Learning: Linear Regression and more Advanced Regression Analysis</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Why Linear Regression (aka Ordinary Least Squares and family)',
               2,
               None,
               '___sec0'),
              ('Regression analysis, overarching aims', 2, None, '___sec1'),
              ('Regression analysis, overarching aims II', 2, None, '___sec2'),
              ('Examples', 2, None, '___sec3'),
              ('General linear models', 2, None, '___sec4'),
              ('Rewriting the fitting procedure as a linear algebra problem',
               2,
               None,
               '___sec5'),
              ('Rewriting the fitting procedure as a linear algebra problem, '
               'more details',
               2,
               None,
               '___sec6'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               '___sec7'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               '___sec8'),
              ('Optimizing our parameters', 2, None, '___sec9'),
              ('Our model for the nuclear binding energies',
               2,
               None,
               '___sec10'),
              ('Optimizing our parameters, more details', 2, None, '___sec11'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               '___sec12'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               '___sec13'),
              ('Some useful matrix and vector expressions',
               2,
               None,
               '___sec14'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               '___sec15'),
              ('Own code for Ordinary Least Squares', 2, None, '___sec16'),
              ('Adding error analysis and training set up',
               2,
               None,
               '___sec17'),
              ('The $\\chi^2$ function', 2, None, '___sec18'),
              ('The $\\chi^2$ function', 2, None, '___sec19'),
              ('The $\\chi^2$ function', 2, None, '___sec20'),
              ('The $\\chi^2$ function', 2, None, '___sec21'),
              ('The $\\chi^2$ function', 2, None, '___sec22'),
              ('The $\\chi^2$ function', 2, None, '___sec23'),
              ('Fitting an Equation of State for Dense Nuclear Matter',
               2,
               None,
               '___sec24'),
              ('The code', 2, None, '___sec25'),
              ('Splitting our Data in Training and Test data',
               2,
               None,
               '___sec26'),
              ('The singular value decomposition', 2, None, '___sec27'),
              ('The Ising model', 2, None, '___sec28'),
              ('Reformulating the problem to suit regression',
               2,
               None,
               '___sec29'),
              ('Linear regression', 2, None, '___sec30'),
              ('Singular Value decomposition', 2, None, '___sec31'),
              ('Linear Regression Problems', 2, None, '___sec32'),
              ('Fixing the singularity', 2, None, '___sec33'),
              ('Basic math of the SVD', 2, None, '___sec34'),
              ('The SVD, a Fantastic Algorithm', 2, None, '___sec35'),
              ('Another Example', 2, None, '___sec36'),
              ('Economy-size SVD', 2, None, '___sec37'),
              ('Mathematical Properties', 2, None, '___sec38'),
              ('Ridge and LASSO Regression', 2, None, '___sec39'),
              ('More on Ridge Regression', 2, None, '___sec40'),
              ('Interpreting the Ridge results', 2, None, '___sec41'),
              ('More interpretations', 2, None, '___sec42'),
              ('Where are we going?', 2, None, '___sec43'),
              ('Resampling methods', 2, None, '___sec44'),
              ('Resampling approaches can be computationally expensive',
               2,
               None,
               '___sec45'),
              ('Why resampling methods ?', 2, None, '___sec46'),
              ('Statistical analysis', 2, None, '___sec47'),
              ('Statistics', 2, None, '___sec48'),
              ('Statistics, moments', 2, None, '___sec49'),
              ('Statistics, central moments', 2, None, '___sec50'),
              ('Statistics, covariance', 2, None, '___sec51'),
              ('Statistics, more covariance', 2, None, '___sec52'),
              ('Statistics, independent variables', 2, None, '___sec53'),
              ('Statistics, more variance', 2, None, '___sec54'),
              ('Statistics and stochastic processes', 2, None, '___sec55'),
              ('Statistics and sample variables', 2, None, '___sec56'),
              ('Statistics, sample variance and covariance',
               2,
               None,
               '___sec57'),
              ('Statistics, law of large numbers', 2, None, '___sec58'),
              ('Statistics, more on sample error', 2, None, '___sec59'),
              ('Statistics', 2, None, '___sec60'),
              ('Statistics, central limit theorem', 2, None, '___sec61'),
              ('Statistics, more technicalities', 2, None, '___sec62'),
              ('Statistics', 2, None, '___sec63'),
              ('Statistics and sample variance', 2, None, '___sec64'),
              ('Statistics, uncorrelated results', 2, None, '___sec65'),
              ('Statistics, computations', 2, None, '___sec66'),
              ('Statistics, more on computations of errors',
               2,
               None,
               '___sec67'),
              ('Statistics, wrapping up 1', 2, None, '___sec68'),
              ('Statistics, final expression', 2, None, '___sec69'),
              ('Statistics, effective number of correlations',
               2,
               None,
               '___sec70'),
              ('Linking the regression analysis with a statistical '
               'interpretation',
               2,
               None,
               '___sec71'),
              ('Assumptions made', 2, None, '___sec72'),
              ('Expectation value and variance', 2, None, '___sec73'),
              ('Expectation value and variance for $\\boldsymbol{\\beta}$',
               2,
               None,
               '___sec74'),
              ('Cross-validation', 2, None, '___sec75'),
              ('Computationally expensive', 2, None, '___sec76'),
              ('Various steps in cross-validation', 2, None, '___sec77'),
              ('How to set up the cross-validation for Ridge and/or Lasso',
               2,
               None,
               '___sec78'),
              ('Resampling methods: Jackknife and Bootstrap',
               2,
               None,
               '___sec79'),
              ('Resampling methods: Jackknife', 2, None, '___sec80'),
              ('Jackknife code example', 2, None, '___sec81'),
              ('Resampling methods: Bootstrap', 2, None, '___sec82'),
              ('Resampling methods: Bootstrap background', 2, None, '___sec83'),
              ('Resampling methods: More Bootstrap background',
               2,
               None,
               '___sec84'),
              ('Resampling methods: Bootstrap approach', 2, None, '___sec85'),
              ('Resampling methods: Bootstrap steps', 2, None, '___sec86'),
              ('Code example for the Bootstrap method', 2, None, '___sec87'),
              ('Code Example for Cross-validation and $k$-fold '
               'Cross-validation',
               2,
               None,
               '___sec88'),
              ('The bias-variance tradeoff', 2, None, '___sec89'),
              ('Example code for Bias-Variance tradeoff', 2, None, '___sec90'),
              ('Understanding what happens', 2, None, '___sec91'),
              ('Summing up', 2, None, '___sec92'),
              ("Another Example rom Scikit-Learn's Repository",
               2,
               None,
               '___sec93'),
              ('The one-dimensional Ising model', 2, None, '___sec94'),
              ('Ridge regression', 2, None, '___sec95'),
              ('LASSO regression', 2, None, '___sec96'),
              ('Performance as  function of the regularization parameter',
               2,
               None,
               '___sec97'),
              ('Finding the optimal value of $\\lambda$', 2, None, '___sec98'),
              ('Further Exercises', 2, None, '___sec99'),
              ('Exercise 1', 3, None, '___sec100'),
              ('Exercise 2, variance of the parameters $\\beta$ in linear '
               'regression',
               3,
               None,
               '___sec101'),
              ('Exercise 3', 3, None, '___sec102'),
              ('Exercise 4', 3, None, '___sec103')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="Regression-bs.html">Data Analysis and Machine Learning: Linear Regression and more Advanced Regression Analysis</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._Regression-bs001.html#___sec0" style="font-size: 80%;"><b>Why Linear Regression (aka Ordinary Least Squares and family)</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs002.html#___sec1" style="font-size: 80%;"><b>Regression analysis, overarching aims</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs003.html#___sec2" style="font-size: 80%;"><b>Regression analysis, overarching aims II</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs004.html#___sec3" style="font-size: 80%;"><b>Examples</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs005.html#___sec4" style="font-size: 80%;"><b>General linear models</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs006.html#___sec5" style="font-size: 80%;"><b>Rewriting the fitting procedure as a linear algebra problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs007.html#___sec6" style="font-size: 80%;"><b>Rewriting the fitting procedure as a linear algebra problem, more details</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs008.html#___sec7" style="font-size: 80%;"><b>Generalizing the fitting procedure as a linear algebra problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs009.html#___sec8" style="font-size: 80%;"><b>Generalizing the fitting procedure as a linear algebra problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs010.html#___sec9" style="font-size: 80%;"><b>Optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs011.html#___sec10" style="font-size: 80%;"><b>Our model for the nuclear binding energies</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs012.html#___sec11" style="font-size: 80%;"><b>Optimizing our parameters, more details</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs013.html#___sec12" style="font-size: 80%;"><b>Interpretations and optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs014.html#___sec13" style="font-size: 80%;"><b>Interpretations and optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs015.html#___sec14" style="font-size: 80%;"><b>Some useful matrix and vector expressions</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs016.html#___sec15" style="font-size: 80%;"><b>Interpretations and optimizing our parameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs017.html#___sec16" style="font-size: 80%;"><b>Own code for Ordinary Least Squares</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs018.html#___sec17" style="font-size: 80%;"><b>Adding error analysis and training set up</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs019.html#___sec18" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs020.html#___sec19" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs021.html#___sec20" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs022.html#___sec21" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs023.html#___sec22" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs024.html#___sec23" style="font-size: 80%;"><b>The \( \chi^2 \) function</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs025.html#___sec24" style="font-size: 80%;"><b>Fitting an Equation of State for Dense Nuclear Matter</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs026.html#___sec25" style="font-size: 80%;"><b>The code</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs027.html#___sec26" style="font-size: 80%;"><b>Splitting our Data in Training and Test data</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs028.html#___sec27" style="font-size: 80%;"><b>The singular value decomposition</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs029.html#___sec28" style="font-size: 80%;"><b>The Ising model</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs030.html#___sec29" style="font-size: 80%;"><b>Reformulating the problem to suit regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs031.html#___sec30" style="font-size: 80%;"><b>Linear regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs032.html#___sec31" style="font-size: 80%;"><b>Singular Value decomposition</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs033.html#___sec32" style="font-size: 80%;"><b>Linear Regression Problems</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs034.html#___sec33" style="font-size: 80%;"><b>Fixing the singularity</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs035.html#___sec34" style="font-size: 80%;"><b>Basic math of the SVD</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs036.html#___sec35" style="font-size: 80%;"><b>The SVD, a Fantastic Algorithm</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs037.html#___sec36" style="font-size: 80%;"><b>Another Example</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs038.html#___sec37" style="font-size: 80%;"><b>Economy-size SVD</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs039.html#___sec38" style="font-size: 80%;"><b>Mathematical Properties</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs040.html#___sec39" style="font-size: 80%;"><b>Ridge and LASSO Regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs041.html#___sec40" style="font-size: 80%;"><b>More on Ridge Regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs042.html#___sec41" style="font-size: 80%;"><b>Interpreting the Ridge results</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs043.html#___sec42" style="font-size: 80%;"><b>More interpretations</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs044.html#___sec43" style="font-size: 80%;"><b>Where are we going?</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs045.html#___sec44" style="font-size: 80%;"><b>Resampling methods</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs046.html#___sec45" style="font-size: 80%;"><b>Resampling approaches can be computationally expensive</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs047.html#___sec46" style="font-size: 80%;"><b>Why resampling methods ?</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs048.html#___sec47" style="font-size: 80%;"><b>Statistical analysis</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs049.html#___sec48" style="font-size: 80%;"><b>Statistics</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs050.html#___sec49" style="font-size: 80%;"><b>Statistics, moments</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs051.html#___sec50" style="font-size: 80%;"><b>Statistics, central moments</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs052.html#___sec51" style="font-size: 80%;"><b>Statistics, covariance</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs053.html#___sec52" style="font-size: 80%;"><b>Statistics, more covariance</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs054.html#___sec53" style="font-size: 80%;"><b>Statistics, independent variables</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs055.html#___sec54" style="font-size: 80%;"><b>Statistics, more variance</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs056.html#___sec55" style="font-size: 80%;"><b>Statistics and stochastic processes</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs057.html#___sec56" style="font-size: 80%;"><b>Statistics and sample variables</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs058.html#___sec57" style="font-size: 80%;"><b>Statistics, sample variance and covariance</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs059.html#___sec58" style="font-size: 80%;"><b>Statistics, law of large numbers</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs060.html#___sec59" style="font-size: 80%;"><b>Statistics, more on sample error</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs061.html#___sec60" style="font-size: 80%;"><b>Statistics</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs062.html#___sec61" style="font-size: 80%;"><b>Statistics, central limit theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs063.html#___sec62" style="font-size: 80%;"><b>Statistics, more technicalities</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs064.html#___sec63" style="font-size: 80%;"><b>Statistics</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs065.html#___sec64" style="font-size: 80%;"><b>Statistics and sample variance</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs066.html#___sec65" style="font-size: 80%;"><b>Statistics, uncorrelated results</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs067.html#___sec66" style="font-size: 80%;"><b>Statistics, computations</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs068.html#___sec67" style="font-size: 80%;"><b>Statistics, more on computations of errors</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs069.html#___sec68" style="font-size: 80%;"><b>Statistics, wrapping up 1</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs070.html#___sec69" style="font-size: 80%;"><b>Statistics, final expression</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs071.html#___sec70" style="font-size: 80%;"><b>Statistics, effective number of correlations</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs072.html#___sec71" style="font-size: 80%;"><b>Linking the regression analysis with a statistical interpretation</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs073.html#___sec72" style="font-size: 80%;"><b>Assumptions made</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs074.html#___sec73" style="font-size: 80%;"><b>Expectation value and variance</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs075.html#___sec74" style="font-size: 80%;"><b>Expectation value and variance for \( \boldsymbol{\beta} \)</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs076.html#___sec75" style="font-size: 80%;"><b>Cross-validation</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs077.html#___sec76" style="font-size: 80%;"><b>Computationally expensive</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs078.html#___sec77" style="font-size: 80%;"><b>Various steps in cross-validation</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs079.html#___sec78" style="font-size: 80%;"><b>How to set up the cross-validation for Ridge and/or Lasso</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs080.html#___sec79" style="font-size: 80%;"><b>Resampling methods: Jackknife and Bootstrap</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs081.html#___sec80" style="font-size: 80%;"><b>Resampling methods: Jackknife</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs082.html#___sec81" style="font-size: 80%;"><b>Jackknife code example</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs083.html#___sec82" style="font-size: 80%;"><b>Resampling methods: Bootstrap</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs084.html#___sec83" style="font-size: 80%;"><b>Resampling methods: Bootstrap background</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs085.html#___sec84" style="font-size: 80%;"><b>Resampling methods: More Bootstrap background</b></a></li>
     <!-- navigation toc: --> <li><a href="#___sec85" style="font-size: 80%;"><b>Resampling methods: Bootstrap approach</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs087.html#___sec86" style="font-size: 80%;"><b>Resampling methods: Bootstrap steps</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs088.html#___sec87" style="font-size: 80%;"><b>Code example for the Bootstrap method</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs089.html#___sec88" style="font-size: 80%;"><b>Code Example for Cross-validation and \( k \)-fold Cross-validation</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs090.html#___sec89" style="font-size: 80%;"><b>The bias-variance tradeoff</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs091.html#___sec90" style="font-size: 80%;"><b>Example code for Bias-Variance tradeoff</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs092.html#___sec91" style="font-size: 80%;"><b>Understanding what happens</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs093.html#___sec92" style="font-size: 80%;"><b>Summing up</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs094.html#___sec93" style="font-size: 80%;"><b>Another Example rom Scikit-Learn's Repository</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs095.html#___sec94" style="font-size: 80%;"><b>The one-dimensional Ising model</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs096.html#___sec95" style="font-size: 80%;"><b>Ridge regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs097.html#___sec96" style="font-size: 80%;"><b>LASSO regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs098.html#___sec97" style="font-size: 80%;"><b>Performance as  function of the regularization parameter</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs099.html#___sec98" style="font-size: 80%;"><b>Finding the optimal value of \( \lambda \)</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs100.html#___sec99" style="font-size: 80%;"><b>Further Exercises</b></a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs100.html#___sec100" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 1</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs100.html#___sec101" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 2, variance of the parameters \( \beta \) in linear regression</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs100.html#___sec102" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 3</a></li>
     <!-- navigation toc: --> <li><a href="._Regression-bs100.html#___sec103" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 4</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0086"></a>
<!-- !split -->

<h2 id="___sec85" class="anchor">Resampling methods: Bootstrap approach </h2>

<p>
But
unless there is enough information available about the process that
generated \( X_1,X_2,\cdots,X_n \), \( p(x) \) is in general
unknown. Therefore, <a href="https://projecteuclid.org/euclid.aos/1176344552" target="_self">Efron in 1979</a>  asked the
question: What if we replace \( p(x) \) by the relative frequency
of the observation \( X_i \); if we draw observations in accordance with
the relative frequency of the observations, will we obtain the same
result in some asymptotic sense? The answer is yes.

<p>
Instead of generating the histogram for the relative
frequency of the observation \( X_i \), just draw the values
\( (X_1^*,X_2^*,\cdots,X_n^*) \) with replacement from the vector
\( \boldsymbol{X} \).

<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._Regression-bs085.html">&laquo;</a></li>
  <li><a href="._Regression-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._Regression-bs078.html">79</a></li>
  <li><a href="._Regression-bs079.html">80</a></li>
  <li><a href="._Regression-bs080.html">81</a></li>
  <li><a href="._Regression-bs081.html">82</a></li>
  <li><a href="._Regression-bs082.html">83</a></li>
  <li><a href="._Regression-bs083.html">84</a></li>
  <li><a href="._Regression-bs084.html">85</a></li>
  <li><a href="._Regression-bs085.html">86</a></li>
  <li class="active"><a href="._Regression-bs086.html">87</a></li>
  <li><a href="._Regression-bs087.html">88</a></li>
  <li><a href="._Regression-bs088.html">89</a></li>
  <li><a href="._Regression-bs089.html">90</a></li>
  <li><a href="._Regression-bs090.html">91</a></li>
  <li><a href="._Regression-bs091.html">92</a></li>
  <li><a href="._Regression-bs092.html">93</a></li>
  <li><a href="._Regression-bs093.html">94</a></li>
  <li><a href="._Regression-bs094.html">95</a></li>
  <li><a href="._Regression-bs095.html">96</a></li>
  <li><a href="">...</a></li>
  <li><a href="._Regression-bs100.html">101</a></li>
  <li><a href="._Regression-bs087.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

