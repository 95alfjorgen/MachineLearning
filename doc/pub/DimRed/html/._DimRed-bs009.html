<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Data Analysis and Machine Learning: Preprocessing and Dimensionality Reduction">

<title>Data Analysis and Machine Learning: Preprocessing and Dimensionality Reduction</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Reducing the number of degrees of freedom, overarching view',
               2,
               None,
               '___sec0'),
              ('Preprocessing our data', 2, None, '___sec1'),
              ('More preprocessing', 2, None, '___sec2'),
              ('Simple preprocessing examples, Franke function and regression',
               2,
               None,
               '___sec3'),
              ('Simple preprocessing examples, breast cancer data and '
               'classification, Support Vector Machines',
               2,
               None,
               '___sec4'),
              ('More on Cancer Data, now with Logistic Regression',
               2,
               None,
               '___sec5'),
              ('Why should we think of reducing the dimensionality',
               2,
               None,
               '___sec6'),
              ('Basic ideas of the Principal Component Analysis (PCA)',
               2,
               None,
               '___sec7'),
              ('Introducing the Covariance and Correlation functions',
               2,
               None,
               '___sec8'),
              ('Correlation Function and Design/Feature Matrix',
               2,
               None,
               '___sec9'),
              ('Covariance Matrix Examples', 2, None, '___sec10'),
              ('Correlation Matrix', 2, None, '___sec11'),
              ('Correlation Matrix with Pandas', 2, None, '___sec12'),
              ('Correlation Matrix with Pandas and the Franke function',
               2,
               None,
               '___sec13'),
              ('Rewriting the Covariance and/or Correlation Matrix',
               2,
               None,
               '___sec14'),
              ('Towards the PCA theorem', 2, None, '___sec15'),
              ('Classical PCA Theorem', 2, None, '___sec16'),
              ('Prof of the PCA Theorem', 2, None, '___sec17'),
              ('Getting started with PCA', 2, None, '___sec18'),
              ('Principal Component Analysis', 2, None, '___sec19'),
              ('PCA and scikit-learn', 2, None, '___sec20'),
              ('More on the PCA', 2, None, '___sec21'),
              ('Incremental PCA', 2, None, '___sec22'),
              ('Randomized PCA', 2, None, '___sec23'),
              ('Kernel PCA', 2, None, '___sec24'),
              ('LLE', 2, None, '___sec25'),
              ('Other techniques', 2, None, '___sec26')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="DimRed-bs.html">Data Analysis and Machine Learning: Preprocessing and Dimensionality Reduction</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._DimRed-bs001.html#___sec0" style="font-size: 80%;">Reducing the number of degrees of freedom, overarching view</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs002.html#___sec1" style="font-size: 80%;">Preprocessing our data</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs003.html#___sec2" style="font-size: 80%;">More preprocessing</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs004.html#___sec3" style="font-size: 80%;">Simple preprocessing examples, Franke function and regression</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs005.html#___sec4" style="font-size: 80%;">Simple preprocessing examples, breast cancer data and classification, Support Vector Machines</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs006.html#___sec5" style="font-size: 80%;">More on Cancer Data, now with Logistic Regression</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs007.html#___sec6" style="font-size: 80%;">Why should we think of reducing the dimensionality</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs008.html#___sec7" style="font-size: 80%;">Basic ideas of the Principal Component Analysis (PCA)</a></li>
     <!-- navigation toc: --> <li><a href="#___sec8" style="font-size: 80%;">Introducing the Covariance and Correlation functions</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs010.html#___sec9" style="font-size: 80%;">Correlation Function and Design/Feature Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs011.html#___sec10" style="font-size: 80%;">Covariance Matrix Examples</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs012.html#___sec11" style="font-size: 80%;">Correlation Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs013.html#___sec12" style="font-size: 80%;">Correlation Matrix with Pandas</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs014.html#___sec13" style="font-size: 80%;">Correlation Matrix with Pandas and the Franke function</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs015.html#___sec14" style="font-size: 80%;">Rewriting the Covariance and/or Correlation Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs016.html#___sec15" style="font-size: 80%;">Towards the PCA theorem</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs017.html#___sec16" style="font-size: 80%;">Classical PCA Theorem</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs018.html#___sec17" style="font-size: 80%;">Prof of the PCA Theorem</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs019.html#___sec18" style="font-size: 80%;">Getting started with PCA</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs020.html#___sec19" style="font-size: 80%;">Principal Component Analysis</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs021.html#___sec20" style="font-size: 80%;">PCA and scikit-learn</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs022.html#___sec21" style="font-size: 80%;">More on the PCA</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs023.html#___sec22" style="font-size: 80%;">Incremental PCA</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs024.html#___sec23" style="font-size: 80%;">Randomized PCA</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs025.html#___sec24" style="font-size: 80%;">Kernel PCA</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs026.html#___sec25" style="font-size: 80%;">LLE</a></li>
     <!-- navigation toc: --> <li><a href="._DimRed-bs027.html#___sec26" style="font-size: 80%;">Other techniques</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0009"></a>
<!-- !split -->

<h2 id="___sec8" class="anchor">Introducing the Covariance and Correlation functions  </h2>

<p>
Before we discuss the PCA theorem, we need to remind ourselves about
the definition of the covariance and the correlation function.

<p>
Suppose we have defined two vectors
\( \hat{x} \) and \( \hat{y} \) with \( n \) elements each. The covariance matrix \( \boldsymbol{C} \) is defined as 
$$
\boldsymbol{C}[\boldsymbol{x},\boldsymbol{y}] = \begin{bmatrix} \mathrm{cov}[\boldsymbol{x},\boldsymbol{x}] & \mathrm{cov}[\boldsymbol{x},\boldsymbol{y}] \\
                              \mathrm{cov}[\boldsymbol{y},\boldsymbol{x}] & \mathrm{cov}[\boldsymbol{y},\boldsymbol{y}] \\
             \end{bmatrix},
$$

where for example
$$
\mathrm{cov}[\boldsymbol{x},\boldsymbol{y}] =\frac{1}{n} \sum_{i=0}^{n-1}(x_i- \overline{x})(y_i- \overline{y}).
$$

With this definition and recalling that the variance is defined as
$$
\mathrm{var}[\boldsymbol{x}]=\frac{1}{n} \sum_{i=0}^{n-1}(x_i- \overline{x})^2,
$$

we can rewrite the covariance matrix as 
$$
\boldsymbol{C}[\boldsymbol{x},\boldsymbol{y}] = \begin{bmatrix} \mathrm{var}[\boldsymbol{x}] & \mathrm{cov}[\boldsymbol{x},\boldsymbol{y}] \\
                              \mathrm{cov}[\boldsymbol{x},\boldsymbol{y}] & \mathrm{var}[\boldsymbol{y}] \\
             \end{bmatrix}.
$$

<p>
The covariance takes values between zero and infinity and may thus
lead to problems with loss of numerical precision for particularly
large values. It is common to scale the covariance matrix by
introducing instead the correlation matrix defined via the so-called
correlation function

$$
\mathrm{corr}[\boldsymbol{x},\boldsymbol{y}]=\frac{\mathrm{cov}[\boldsymbol{x},\boldsymbol{y}]}{\sqrt{\mathrm{var}[\boldsymbol{x}] \mathrm{var}[\boldsymbol{y}]}}.
$$

<p>
The correlation function is then given by values \( \mathrm{corr}[\boldsymbol{x},\boldsymbol{y}]
\in [-1,1] \). This avoids eventual problems with too large values. We
can then define the correlation matrix for the two vectors \( \boldsymbol{x} \)
and \( \boldsymbol{y} \) as

$$
\boldsymbol{K}[\boldsymbol{x},\boldsymbol{y}] = \begin{bmatrix} 1 & \mathrm{corr}[\boldsymbol{x},\boldsymbol{y}] \\
                              \mathrm{corr}[\boldsymbol{y},\boldsymbol{x}] & 1 \\
             \end{bmatrix},
$$

<p>
In the above example this is the function we constructed using <b>pandas</b>.

<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._DimRed-bs008.html">&laquo;</a></li>
  <li><a href="._DimRed-bs000.html">1</a></li>
  <li><a href="._DimRed-bs001.html">2</a></li>
  <li><a href="._DimRed-bs002.html">3</a></li>
  <li><a href="._DimRed-bs003.html">4</a></li>
  <li><a href="._DimRed-bs004.html">5</a></li>
  <li><a href="._DimRed-bs005.html">6</a></li>
  <li><a href="._DimRed-bs006.html">7</a></li>
  <li><a href="._DimRed-bs007.html">8</a></li>
  <li><a href="._DimRed-bs008.html">9</a></li>
  <li class="active"><a href="._DimRed-bs009.html">10</a></li>
  <li><a href="._DimRed-bs010.html">11</a></li>
  <li><a href="._DimRed-bs011.html">12</a></li>
  <li><a href="._DimRed-bs012.html">13</a></li>
  <li><a href="._DimRed-bs013.html">14</a></li>
  <li><a href="._DimRed-bs014.html">15</a></li>
  <li><a href="._DimRed-bs015.html">16</a></li>
  <li><a href="._DimRed-bs016.html">17</a></li>
  <li><a href="._DimRed-bs017.html">18</a></li>
  <li><a href="._DimRed-bs018.html">19</a></li>
  <li><a href="">...</a></li>
  <li><a href="._DimRed-bs027.html">28</a></li>
  <li><a href="._DimRed-bs010.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

