{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: Summary of course -->\n",
    "# Summary of course\n",
    "<!-- dom:AUTHOR: Morten Hjorth-Jensen   Email morten.hjorth-jensen@fys.uio.no at Department of Physics and Center of Mathematics for Applications, University of Oslo & National Superconducting Cyclotron Laboratory, Michigan State University -->\n",
    "<!-- Author: -->  \n",
    "**Morten Hjorth-Jensen   Email morten.hjorth-jensen@fys.uio.no**, Department of Physics and Center of Mathematics for Applications, University of Oslo and National Superconducting Cyclotron Laboratory, Michigan State University\n",
    "\n",
    "Date: **Nov 27, 2019**\n",
    "\n",
    "Copyright 1999-2019, Morten Hjorth-Jensen   Email morten.hjorth-jensen@fys.uio.no. Released under CC Attribution-NonCommercial 4.0 license\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## What? Me worry? No final exam in this course!\n",
    "<!-- dom:FIGURE: [figures/exam1.jpeg, width=500 frac=0.6] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<p></p>\n",
    "<img src=\"figures/exam1.jpeg\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "<!-- dom:FIGURE: [figures/whatmeworry.jpeg, width=500 frac=0.6] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<p></p>\n",
    "<img src=\"figures/whatmeworry.jpeg\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "\n",
    "## What did I learn in school this year?\n",
    "\n",
    "[Our ideal about knowledge on computational science](http://hplgit.github.io/edu/py_vs_m/computing_competence.html)\n",
    "\n",
    "\n",
    "Does that match the experiences you have made this semester?\n",
    "<!-- dom:FIGURE: [figures/exam2.jpg, width=500 frac=0.7] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<p></p>\n",
    "<img src=\"figures/exam2.jpg\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "## Topics we have covered this year\n",
    "\n",
    "The course has two central parts\n",
    "\n",
    "1. Statistical analysis and optimization of data\n",
    "\n",
    "2. Machine learning\n",
    "\n",
    "## Statistical analysis and optimization of data\n",
    "\n",
    "The following topics will be covered\n",
    "1. Basic concepts, expectation values, variance, covariance, correlation functions and errors;\n",
    "\n",
    "2. Simpler models, binomial distribution, the Poisson distribution, simple and multivariate normal distributions;\n",
    "\n",
    "3. Central elements of Bayesian statistics and modeling;\n",
    "\n",
    "4. Central elements from linear algebra\n",
    "\n",
    "5. Gradient methods for data optimization\n",
    "\n",
    "6. Estimation of errors using cross-validation, blocking, bootstrapping and jackknife methods;\n",
    "\n",
    "7. Practical optimization using Singular-value decomposition and least squares for parameterizing data.\n",
    "\n",
    "8. Principal Component Analysis.\n",
    "\n",
    "## Machine learning\n",
    "\n",
    "The following topics will be covered\n",
    "1. Linear methods for regression and classification;\n",
    "\n",
    "2. Neural networks;\n",
    "\n",
    "3. Decisions trees, random forests, boosting and bagging\n",
    "\n",
    "4. Support vector machines\n",
    "\n",
    "## Learning outcomes and overarching aims of this course\n",
    "\n",
    "The course introduces a variety of central algorithms and methods\n",
    "essential for studies of data analysis and machine learning. The\n",
    "course is project based and through the various projects, normally\n",
    "three, you will be exposed to fundamental research problems\n",
    "in these fields, with the aim to reproduce state of the art scientific\n",
    "results. The students will learn to develop and structure large codes\n",
    "for studying these systems, get acquainted with computing facilities\n",
    "and learn to handle large scientific projects. A good scientific and\n",
    "ethical conduct is emphasized throughout the course. \n",
    "\n",
    "* Understand linear methods for regression and classification;\n",
    "\n",
    "* Learn about neural network;\n",
    "\n",
    "* Learn about baggin, boosting and trees\n",
    "\n",
    "* Support vector machines\n",
    "\n",
    "* Learn about basic data analysis;\n",
    "\n",
    "* Be capable of extending the acquired knowledge to other systems and cases;\n",
    "\n",
    "* Have an understanding of central algorithms used in data analysis and machine learning;\n",
    "\n",
    "* Work on numerical projects to illustrate the theory. The projects play a central role and you are expected to know modern programming languages like Python or C++.\n",
    "\n",
    "## Perspective on Machine Learning\n",
    "\n",
    "1. Rapidly emerging application area\n",
    "\n",
    "2. Experiment AND theory are evolving in many many fields. Still many low-hanging fruits.\n",
    "\n",
    "3. Requires education/retraining for more widespread adoption\n",
    "\n",
    "4. A lot of “word-of-mouth” development methods\n",
    "\n",
    "Huge amounts of data sets require automation, classical analysis tools often inadequate. \n",
    "High energy physics hit this wall in the 90’s.\n",
    "In 2009 single top quark production was determined via [Boosted decision trees, Bayesian\n",
    "Neural Networks, etc.](https://arxiv.org/pdf/0903.0850.pdf)\n",
    "\n",
    "\n",
    "## Machine Learning Research\n",
    "\n",
    "Where to find recent results:\n",
    "1. Conference proceedings, arXiv and blog posts!\n",
    "\n",
    "2. **NIPS**: [Neural Information Processing Systems](https://papers.nips.cc)\n",
    "\n",
    "3. **ICLR**: [International Conference on Learning Representations](https://openreview.net/group?id=ICLR.cc/2018/Conference#accepted-oral-papers)\n",
    "\n",
    "4. **ICML**: International Conference on Machine Learning\n",
    "\n",
    "5. [Journal of Machine Learning Research](http://www.jmlr.org/papers/v19/) \n",
    "\n",
    "## Starting your Machine Learning Project\n",
    "\n",
    "1. Identify problem type: classification, generation, regression\n",
    "\n",
    "2. Consider your data carefully\n",
    "\n",
    "3. Choose a simple model that fits 1. and 2.\n",
    "\n",
    "4. Consider your data carefully again… data representation\n",
    "\n",
    "5. Based on results, feedback loop to earliest possible point\n",
    "\n",
    "## Choose a Model and Algorithm\n",
    "\n",
    "1. Supervised?\n",
    "\n",
    "2. Start with the simplest model that fits your problem\n",
    "\n",
    "3. Start with minimal processing of data\n",
    "\n",
    "## Preparing Your Data\n",
    "\n",
    "1. Shuffle your data\n",
    "\n",
    "2. Mean center your data\n",
    "\n",
    "  * Why?\n",
    "\n",
    "\n",
    "3. Normalize the variance\n",
    "\n",
    "  * Why?\n",
    "\n",
    "\n",
    "4. **Whitening**\n",
    "\n",
    "  * Decorrelates data\n",
    "\n",
    "  * Can be hit or miss\n",
    "\n",
    "\n",
    "5. When to do train/test split?\n",
    "\n",
    "## Which Activation and Weights to Choose in Neural Networks\n",
    "\n",
    "1. RELU? ELU?\n",
    "\n",
    "2. Sigmoid or Tanh?\n",
    "\n",
    "3. Set all weights to 0?\n",
    "\n",
    "  * Terrible idea\n",
    "\n",
    "\n",
    "4. Set all weights to random values?\n",
    "\n",
    "  * Small random values\n",
    "\n",
    "\n",
    "## Optimization Methods and Hyperparameters\n",
    "1. Stochastic gradient descent\n",
    "\n",
    "a. Stochastic gradient descent + momentum\n",
    "\n",
    "\n",
    "2. State-of-the-art approaches:\n",
    "\n",
    "  * RMSProp\n",
    "\n",
    "  * Adam\n",
    "\n",
    "\n",
    "Which regularization and hyperparameters? $L_1$ or $L_2$, soft classifiers, depths of trees and many other. Need to explore a large set of hyperparameters and regularization methods. \n",
    "\n",
    "\n",
    "## Resampling\n",
    "\n",
    "When do we resample?\n",
    "\n",
    "1. Bootstrap\n",
    "\n",
    "2. Cross-validation\n",
    "\n",
    "3. Jackknife and many other\n",
    "\n",
    "## Other courses on Data science and Machine Learning  at UiO\n",
    "\n",
    "The link here <https://www.mn.uio.no/english/research/about/centre-focus/innovation/data-science/studies/>  gives an excellent overview of courses on Machine learning at UiO.\n",
    "\n",
    "1. [STK2100 Machine learning and statistical methods for prediction and classification](http://www.uio.no/studier/emner/matnat/math/STK2100/index-eng.html). \n",
    "\n",
    "2. [IN3050/IN4050 Introduction to Artificial Intelligence and Machine Learning](https://www.uio.no/studier/emner/matnat/ifi/IN3050/index-eng.html). Introductory course in machine learning and AI with an algorithmic approach. \n",
    "\n",
    "3. [STK-INF3000/4000 Selected Topics in Data Science](http://www.uio.no/studier/emner/matnat/math/STK-INF3000/index-eng.html). The course provides insight into selected contemporary relevant topics within Data Science. \n",
    "\n",
    "4. [IN4080 Natural Language Processing](https://www.uio.no/studier/emner/matnat/ifi/IN4080/index.html). Probabilistic and machine learning techniques applied to natural language processing. \n",
    "\n",
    "5. [STK-IN4300 – Statistical learning methods in Data Science](https://www.uio.no/studier/emner/matnat/math/STK-IN4300/index-eng.html). An advanced introduction to statistical and machine learning. For students with a good mathematics and statistics background.\n",
    "\n",
    "6. [IN-STK5000  Adaptive Methods for Data-Based Decision Making](https://www.uio.no/studier/emner/matnat/ifi/IN-STK5000/index-eng.html). Methods for adaptive collection and processing of data based on machine learning techniques. \n",
    "\n",
    "7. [IN5400/INF5860 – Machine Learning for Image Analysis](https://www.uio.no/studier/emner/matnat/ifi/IN5400/). An introduction to deep learning with particular emphasis on applications within Image analysis, but useful for other application areas too.\n",
    "\n",
    "8. [TEK5040 – Dyp læring for autonome systemer](https://www.uio.no/studier/emner/matnat/its/TEK5040/). The course addresses advanced algorithms and architectures for deep learning with neural networks. The course provides an introduction to how deep-learning techniques can be used in the construction of key parts of advanced autonomous systems that exist in physical environments and cyber environments.\n",
    "\n",
    "## Additional courses of interest\n",
    "\n",
    "1. [STK4051 Computational Statistics](https://www.uio.no/studier/emner/matnat/math/STK4051/index-eng.html)\n",
    "\n",
    "2. [STK4021 Applied Bayesian Analysis and Numerical Methods](https://www.uio.no/studier/emner/matnat/math/STK4021/index-eng.html)\n",
    "\n",
    "## What's the future like?\n",
    "\n",
    "Based on multi-layer nonlinear neural networks, deep learning can\n",
    "learn directly from raw data, automatically extract and abstract\n",
    "features from layer to layer, and then achieve the goal of regression,\n",
    "classification, or ranking. Deep learning has made breakthroughs in\n",
    "computer vision, speech processing and natural language, and reached\n",
    "or even surpassed human level. The success of deep learning is mainly\n",
    "due to the three factors: big data, big model, and big computing.\n",
    "\n",
    "In the past few decades, many different architectures of deep neural\n",
    "networks have been proposed, such as\n",
    "1. Convolutional neural networks, which are mostly used in image and video data processing, and have also been applied to sequential data such as text processing;\n",
    "\n",
    "2. Recurrent neural networks, which can process sequential data of variable length and have been widely used in natural language understanding and speech processing;\n",
    "\n",
    "3. Encoder-decoder framework, which is mostly used for image or sequence generation, such as machine translation, text summarization, and image captioning.\n",
    "\n",
    "## Reinforcement Learning\n",
    "\n",
    "Reinforcement learning is a sub-area of machine learning. It studies\n",
    "how agents take actions based on trial and error, so as to maximize\n",
    "some notion of cumulative reward in a dynamic system or\n",
    "environment. Due to its generality, the problem has also been studied\n",
    "in many other disciplines, such as game theory, control theory,\n",
    "operations research, information theory, multi-agent systems, swarm\n",
    "intelligence, statistics, and genetic algorithms.\n",
    "\n",
    "In March 2016, AlphaGo, a computer program that plays the board game\n",
    "Go, beat Lee Sedol in a five-game match. This was the first time a\n",
    "computer Go program had beaten a 9-dan (highest rank) professional\n",
    "without handicaps. AlphaGo is based on deep convolutional neural\n",
    "networks and reinforcement learning. AlphaGo’s victory was a major\n",
    "milestone in artificial intelligence and it has also made\n",
    "reinforcement learning a hot research area in the field of machine\n",
    "learning.\n",
    "\n",
    "## Transfer learning\n",
    "\n",
    "The goal of transfer learning is to transfer the model or knowledge\n",
    "obtained from a source task to the target task, in order to resolve\n",
    "the issues of insufficient training data in the target task. The\n",
    "rationality of doing so lies in that usually the source and target\n",
    "tasks have inter-correlations, and therefore either the features,\n",
    "samples, or models in the source task might provide useful information\n",
    "for us to better solve the target task. Transfer learning is a hot\n",
    "research topic in recent years, with many problems still waiting to be\n",
    "solved in this space.\n",
    "\n",
    "\n",
    "## Adversarial learning\n",
    "\n",
    "The conventional deep generative model has a potential problem: the\n",
    "model tends to generate extreme instances to maximize the\n",
    "probabilistic likelihood, which will hurt its performance. Adversarial\n",
    "learning utilizes the adversarial behaviors (e.g., generating\n",
    "adversarial instances or training an adversarial model) to enhance the\n",
    "robustness of the model and improve the quality of the generated\n",
    "data. In recent years, one of the most promising unsupervised learning\n",
    "technologies, generative adversarial networks (GAN), has already been\n",
    "successfully applied to image, speech, and text.\n",
    "\n",
    "## Dual learning\n",
    "\n",
    "Dual learning is a new learning paradigm, the basic idea of which is\n",
    "to use the primal-dual structure between machine learning tasks to\n",
    "obtain effective feedback/regularization, and guide and strengthen the\n",
    "learning process, thus reducing the requirement of large-scale labeled\n",
    "data for deep learning. The idea of dual learning has been applied to\n",
    "many problems in machine learning, including machine translation,\n",
    "image style conversion, question answering and generation, image\n",
    "classification and generation, text classification and generation,\n",
    "image-to-text, and text-to-image.\n",
    "\n",
    "## Distributed machine learning\n",
    "\n",
    "Distributed computation will speed up machine learning algorithms,\n",
    "significantly improve their efficiency, and thus enlarge their\n",
    "application. When distributed meets machine learning, more than just\n",
    "implementing the machine learning algorithms in parallel is required.\n",
    "\n",
    "\n",
    "## Meta learning\n",
    "\n",
    "Meta learning is an emerging research direction in machine\n",
    "learning. Roughly speaking, meta learning concerns learning how to\n",
    "learn, and focuses on the understanding and adaptation of the learning\n",
    "itself, instead of just completing a specific learning task. That is,\n",
    "a meta learner needs to be able to evaluate its own learning methods\n",
    "and adjust its own learning methods according to specific learning\n",
    "tasks.\n",
    "\n",
    "## The Challenges Facing Machine Learning\n",
    "\n",
    "While there has been much progress in machine learning, there are also challenges.\n",
    "\n",
    "For example, the mainstream machine learning technologies are\n",
    "black-box approaches, making us concerned about their potential\n",
    "risks. To tackle this challenge, we may want to make machine learning\n",
    "more explainable and controllable. As another example, the\n",
    "computational complexity of machine learning algorithms is usually\n",
    "very high and we may want to invent lightweight algorithms or\n",
    "implementations. Furthermore, in many domains such as physics,\n",
    "chemistry, biology, and social sciences, people usually seek elegantly\n",
    "simple equations (e.g., the Schrödinger equation) to uncover the\n",
    "underlying laws behind various phenomena. In the field of machine\n",
    "learning, can we reveal simple laws instead of designing more complex\n",
    "models for data fitting? Although there are many challenges, we are\n",
    "still very optimistic about the future of machine learning. As we look\n",
    "forward to the future, here are what we think the research hotspots in\n",
    "the next ten years will be.\n",
    "\n",
    "\n",
    "## Explainable machine learning\n",
    "\n",
    "Machine learning, especially deep learning, evolves rapidly. The\n",
    "ability gap between machine and human on many complex cognitive tasks\n",
    "becomes narrower and narrower. However, we are still in the very early\n",
    "stage in terms of explaining why those effective models work and how\n",
    "they work.\n",
    "\n",
    "What is missing: the gap between correlation and causation Most\n",
    "machine learning techniques, especially the statistical ones, depend\n",
    "highly on data correlation to make predictions and analyses. In\n",
    "contrast, rational humans tend to reply on clear and trustworthy\n",
    "causality relations obtained via logical reasoning on real and clear\n",
    "facts. It is one of the core goals of explainable machine learning to\n",
    "transition from solving problems by data correlation to solving\n",
    "problems by logical reasoning.\n",
    "\n",
    "## Quantum machine learning\n",
    "\n",
    "Quantum machine learning is an emerging interdisciplinary research\n",
    "area at the intersection of quantum computing and machine learning.\n",
    "\n",
    "Quantum computers use effects such as quantum coherence and quantum\n",
    "entanglement to process information, which is fundamentally different\n",
    "from classical computers. Quantum algorithms have surpassed the best\n",
    "classical algorithms in several problems (e.g., searching for an\n",
    "unsorted database, inverting a sparse matrix), which we call quantum\n",
    "acceleration.\n",
    "\n",
    "When quantum computing meets machine learning, it can be a mutually\n",
    "beneficial and reinforcing process, as it allows us to take advantage\n",
    "of quantum computing to improve the performance of classical machine\n",
    "learning algorithms. In addition, we can also use the machine learning\n",
    "algorithms (on classic computers) to analyze and improve quantum\n",
    "computing systems.\n",
    "\n",
    "\n",
    "## Quantum machine learning algorithms based on linear algebra\n",
    "\n",
    "Many quantum machine learning algorithms are based on variants of\n",
    "quantum algorithms for solving linear equations, which can efficiently\n",
    "solve N-variable linear equations with complexity of O(log2 N) under\n",
    "certain conditions. The quantum matrix inversion algorithm can\n",
    "accelerate many machine learning methods, such as least square linear\n",
    "regression, least square version of support vector machine, Gaussian\n",
    "process, and more. The training of these algorithms can be simplified\n",
    "to solve linear equations. The key bottleneck of this type of quantum\n",
    "machine learning algorithms is data input—that is, how to initialize\n",
    "the quantum system with the entire data set. Although efficient\n",
    "data-input algorithms exist for certain situations, how to efficiently\n",
    "input data into a quantum system is as yet unknown for most cases.\n",
    "\n",
    "## Quantum reinforcement learning\n",
    "\n",
    "In quantum reinforcement learning, a quantum agent interacts with the\n",
    "classical environment to obtain rewards from the environment, so as to\n",
    "adjust and improve its behavioral strategies. In some cases, it\n",
    "achieves quantum acceleration by the quantum processing capabilities\n",
    "of the agent or the possibility of exploring the environment through\n",
    "quantum superposition. Such algorithms have been proposed in\n",
    "superconducting circuits and systems of trapped ions.\n",
    "\n",
    "## Quantum deep learning\n",
    "\n",
    "Dedicated quantum information processors, such as quantum annealers\n",
    "and programmable photonic circuits, are well suited for building deep\n",
    "quantum networks. The simplest deep quantum network is the Boltzmann\n",
    "machine. The classical Boltzmann machine consists of bits with tunable\n",
    "interactions and is trained by adjusting the interaction of these bits\n",
    "so that the distribution of its expression conforms to the statistics\n",
    "of the data. To quantize the Boltzmann machine, the neural network can\n",
    "simply be represented as a set of interacting quantum spins that\n",
    "correspond to an adjustable Ising model. Then, by initializing the\n",
    "input neurons in the Boltzmann machine to a fixed state and allowing\n",
    "the system to heat up, we can read out the output qubits to get the\n",
    "result.\n",
    "\n",
    "\n",
    "## Social machine learning\n",
    "\n",
    "Machine learning aims to imitate how humans\n",
    "learn. While we have developed successful machine learning algorithms,\n",
    "until now we have ignored one important fact: humans are social. Each\n",
    "of us is one part of the total society and it is difficult for us to\n",
    "live, learn, and improve ourselves, alone and isolated. Therefore, we\n",
    "should design machines with social properties. Can we let machines\n",
    "evolve by imitating human society so as to achieve more effective,\n",
    "intelligent, interpretable “social machine learning”?\n",
    "\n",
    "And much more.\n",
    "\n",
    "## The last words?\n",
    "\n",
    "Early computer scientist Alan Kay said, **The best way to predict the\n",
    "future is to create it**. Therefore, all machine learning\n",
    "practitioners, whether scholars or engineers, professors or students,\n",
    "need to work together to advance these important research\n",
    "topics. Together, we will not just predict the future, but create it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Best wishes to you all and thanks so much for your heroic efforts this semester\n",
    "\n",
    "<!-- dom:FIGURE: [figures/Nebbdyr2.png, width=500 frac=0.6] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<p></p>\n",
    "<img src=\"figures/Nebbdyr2.png\" width=500>\n",
    "\n",
    "<!-- end figure -->"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
