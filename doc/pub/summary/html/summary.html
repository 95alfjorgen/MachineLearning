<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Summary of course">

<title>Summary of course</title>


<style type="text/css">
/* bloodish style */

body {
  font-family: Helvetica, Verdana, Arial, Sans-serif;
  color: #404040;
  background: #ffffff;
}
h1 { font-size: 1.8em;  color: #8A0808; }
h2 { font-size: 1.6em;  color: #8A0808; }
h3 { font-size: 1.4em;  color: #8A0808; }
h4 { color: #8A0808; }
a { color: #8A0808; text-decoration:none; }
tt { font-family: "Courier New", Courier; }
/* pre style removed because it will interfer with pygments */
p { text-indent: 0px; }
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-style: normal; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}

div { text-align: justify; text-justify: inter-word; }
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('What? Me worry? No final exam in this course!',
               2,
               None,
               '___sec0'),
              ('What did I learn in school this year?', 2, None, '___sec1'),
              ('Topics we have covered this year', 2, None, '___sec2'),
              ('Statistical analysis and optimization of data',
               2,
               None,
               '___sec3'),
              ('Machine learning', 2, None, '___sec4'),
              ('Learning outcomes and overarching aims of this course',
               2,
               None,
               '___sec5'),
              ('Perspective on Machine Learning', 2, None, '___sec6'),
              ('Machine Learning Research', 2, None, '___sec7'),
              ('Hot Topics Now', 2, None, '___sec8'),
              ('Starting your Machine Learning Project', 2, None, '___sec9'),
              ('Choose a Model and Algorithm', 2, None, '___sec10'),
              ('Preparing Your Data', 2, None, '___sec11'),
              ('Which Activation and Weights to Choose in Neural Networks',
               2,
               None,
               '___sec12'),
              ('Optimization Methods and Hyperparameters', 2, None, '___sec13'),
              ('Resampling', 2, None, '___sec14'),
              ('Other courses on Data science and Machine Learning  at UiO',
               2,
               None,
               '___sec15'),
              ('Additional courses of interest', 2, None, '___sec16'),
              ('Best wishes to you all and thanks so much for your heroic '
               'efforts this semester',
               2,
               None,
               '___sec17')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- ------------------- main content ---------------------- -->



<center><h1>Summary of course</h1></center>  <!-- document title -->

<p>
<!-- author(s): Morten Hjorth-Jensen   Email morten.hjorth-jensen@fys.uio.no -->

<center>
<b>Morten Hjorth-Jensen   Email morten.hjorth-jensen@fys.uio.no</b> [1, 2]
</center>

<p>
<!-- institution(s) -->

<center>[1] <b>Department of Physics and Center of Mathematics for Applications, University of Oslo</b></center>
<center>[2] <b>National Superconducting Cyclotron Laboratory, Michigan State University</b></center>
<br>
<p>
<center><h4>Nov 27, 2019</h4></center> <!-- date -->
<br>
<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec0">What? Me worry? No final exam in this course! </h2>
<br /><br /><center><p><img src="figures/exam1.jpeg" align="bottom" width=500></p></center><br /><br />
<br /><br /><center><p><img src="figures/whatmeworry.jpeg" align="bottom" width=500></p></center><br /><br />

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec1">What did I learn in school this year? </h2>

<p>
<a href="http://hplgit.github.io/edu/py_vs_m/computing_competence.html" target="_blank">Our ideal about knowledge on computational science</a>

<p>
Does that match the experiences you have made this semester?
<br /><br /><center><p><img src="figures/exam2.jpg" align="bottom" width=500></p></center><br /><br />

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec2">Topics we have covered this year </h2>

<p>
The course has two central parts

<ol>
<li> Statistical analysis and optimization of data</li>
<li> Machine learning</li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec3">Statistical analysis and optimization of data </h2>

<p>
The following topics will be covered

<ol>
<li> Basic concepts, expectation values, variance, covariance, correlation functions and errors;</li>
<li> Simpler models, binomial distribution, the Poisson distribution, simple and multivariate normal distributions;</li>
<li> Central elements of Bayesian statistics and modeling;</li>
<li> Central elements from linear algebra</li>
<li> Gradient methods for data optimization</li>
<li> Estimation of errors using cross-validation, blocking, bootstrapping and jackknife methods;</li>
<li> Practical optimization using Singular-value decomposition and least squares for parameterizing data.</li>
<li> Principal Component Analysis.</li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec4">Machine learning </h2>

<p>
The following topics will be covered

<ol>
<li> Linear methods for regression and classification;</li>
<li> Neural networks;</li>
<li> Decisions trees, random forests, boosting and bagging</li>
<li> Support vector machines</li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec5">Learning outcomes and overarching aims of this course </h2>

<p>
The course introduces a variety of central algorithms and methods
essential for studies of data analysis and machine learning. The
course is project based and through the various projects, normally
three, you will be exposed to fundamental research problems
in these fields, with the aim to reproduce state of the art scientific
results. The students will learn to develop and structure large codes
for studying these systems, get acquainted with computing facilities
and learn to handle large scientific projects. A good scientific and
ethical conduct is emphasized throughout the course. 

<ul>
<li> Understand linear methods for regression and classification;</li>
<li> Learn about neural network;</li>
<li> Learn about baggin, boosting and trees</li>
<li> Support vector machines</li>
<li> Learn about basic data analysis;</li>
<li> Be capable of extending the acquired knowledge to other systems and cases;</li>
<li> Have an understanding of central algorithms used in data analysis and machine learning;</li>
<li> Work on numerical projects to illustrate the theory. The projects play a central role and you are expected to know modern programming languages like Python or C++.</li>
</ul>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec6">Perspective on Machine Learning </h2>

<ol>
<li> Rapidly emerging application area</li>
<li> Experiment AND theory are evolving in many many fields. Still many low-hanging fruits.</li>
<li> Requires education/retraining for more widespread adoption</li>
<li> A lot of &#8220;word-of-mouth&#8221; development methods</li>
</ol>

Huge amounts of data sets require automation, classical analysis tools often inadequate. 
High energy physics hit this wall in the 90&#8217;s.
In 2009 single top quark production was determined via <a href="https://arxiv.org/pdf/0903.0850.pdf" target="_blank">Boosted decision trees, Bayesian
Neural Networks, etc.</a>

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec7">Machine Learning Research </h2>

<p>
Where to find recent results:

<ol>
<li> Conference proceedings, arXiv and blog posts!</li>
<li> <b>NIPS</b>: <a href="https://papers.nips.cc" target="_blank">Neural Information Processing Systems</a></li>
<li> <b>ICLR</b>: <a href="https://openreview.net/group?id=ICLR.cc/2018/Conference#accepted-oral-papers" target="_blank">International Conference on Learning Representations</a></li>
<li> <b>ICML</b>: International Conference on Machine Learning</li>
<li> <a href="http://www.jmlr.org/papers/v19/" target="_blank">Journal of Machine Learning Research</a></li> 
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec8">Hot Topics Now </h2>

<ol>
<li> Boosting techniques and complex neural networks</li>
<li> <a href="https://medium.com/@ml.at.berkeley/trickingneural-networks-create-your-own-adversarial-examples-a61eb7620fd8" target="_blank">Adversarial examples</a></li>
<li> <a href="https://arxiv.org/pdf/1707.00600" target="_blank">Zero shot learning</a></li>
<li> Transfer learning</li>
<li> <a href="https://christophm.github.io/interpretable-mlbook/interpretability.html" target="_blank">Model interpretability</a></li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec9">Starting your Machine Learning Project  </h2>

<ol>
<li> Identify problem type: classification, generation, regression</li>
<li> Consider your data carefully</li>
<li> Choose a simple model that fits 1. and 2.</li>
<li> Consider your data carefully again&#8230; data representation</li>
<li> Based on results, feedback loop to earliest possible point</li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec10">Choose a Model and Algorithm  </h2>

<ol>
<li> Supervised?</li>
<li> Start with the simplest model that fits your problem</li>
<li> Start with minimal processing of data</li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec11">Preparing Your Data </h2>

<ol>
<li> Shuffle your data</li>
<li> Mean center your data</li>

<ul>
  <li> Why?</li>
</ul>

<li> Normalize the variance</li>

<ul>
  <li> Why?</li>
</ul>

<li> <b>Whitening</b></li>

<ul>
  <li> Decorrelates data</li>
  <li> Can be hit or miss</li>
</ul>

<li> When to do train/test split?</li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec12">Which Activation and Weights to Choose in Neural Networks </h2>

<ol>
<li> RELU? ELU?</li>
<li> Sigmoid or Tanh?</li>
<li> Set all weights to 0?</li>

<ul>
  <li> Terrible idea</li>
</ul>

<li> Set all weights to random values?</li>

<ul>
  <li> Small random values</li>
</ul>

</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec13">Optimization Methods and Hyperparameters </h2>

<ol>
<li> Stochastic gradient descent

<ol type="a"></li>
<li> Stochastic gradient descent + momentum</li>
</ol>

<li> State-of-the-art approaches:</li>

<ul>
  <li> RMSProp</li>
  <li> Adam</li>
</ul>

</ol>

Which regularization and hyperparameters? \( L_1 \) or \( L_2 \), soft classifiers, depths of trees and many other. Need to explore a large set of hyperparameters and regularization methods.

<p>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec14">Resampling </h2>

<p>
When do we resample?

<ol>
<li> Bootstrap</li>
<li> Cross-validation</li>
<li> Jackknife and many other</li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec15">Other courses on Data science and Machine Learning  at UiO </h2>

<p>
The link here <a href="https://www.mn.uio.no/english/research/about/centre-focus/innovation/data-science/studies/" target="_blank"><tt>https://www.mn.uio.no/english/research/about/centre-focus/innovation/data-science/studies/</tt></a>  gives an excellent overview of courses on Machine learning at UiO.

<ol>
<li> <a href="http://www.uio.no/studier/emner/matnat/math/STK2100/index-eng.html" target="_blank">STK2100 Machine learning and statistical methods for prediction and classification</a>.</li> 
<li> <a href="https://www.uio.no/studier/emner/matnat/ifi/IN3050/index-eng.html" target="_blank">IN3050 Introduction to Artificial Intelligence and Machine Learning</a>. Introductory course in machine learning and AI with an algorithmic approach.</li> 
<li> <a href="http://www.uio.no/studier/emner/matnat/math/STK-INF3000/index-eng.html" target="_blank">STK-INF3000/4000 Selected Topics in Data Science</a>. The course provides insight into selected contemporary relevant topics within Data Science.</li> 
<li> <a href="https://www.uio.no/studier/emner/matnat/ifi/IN4080/index.html" target="_blank">IN4080 Natural Language Processing</a>. Probabilistic and machine learning techniques applied to natural language processing.</li> 
<li> <a href="https://www.uio.no/studier/emner/matnat/math/STK-IN4300/index-eng.html" target="_blank">STK-IN4300 &#8211; Statistical learning methods in Data Science</a>. An advanced introduction to statistical and machine learning. For students with a good mathematics and statistics background.</li>
<li> <a href="http://www.uio.no/studier/emner/matnat/ifi/INF4490/" target="_blank">INF4490 Biologically Inspired Computing</a>. An introduction to self-adapting methods also called artificial intelligence or machine learning.</li> 
<li> <a href="https://www.uio.no/studier/emner/matnat/ifi/IN-STK5000/index-eng.html" target="_blank">IN-STK5000  Adaptive Methods for Data-Based Decision Making</a>. Methods for adaptive collection and processing of data based on machine learning techniques.</li> 
<li> <a href="https://www.uio.no/studier/emner/matnat/ifi/IN5400/" target="_blank">IN5400/INF5860 &#8211; Machine Learning for Image Analysis</a>. An introduction to deep learning with particular emphasis on applications within Image analysis, but useful for other application areas too.</li>
<li> <a href="https://www.uio.no/studier/emner/matnat/its/TEK5040/" target="_blank">TEK5040 &#8211; Dyp l&#230;ring for autonome systemer</a>. The course addresses advanced algorithms and architectures for deep learning with neural networks. The course provides an introduction to how deep-learning techniques can be used in the construction of key parts of advanced autonomous systems that exist in physical environments and cyber environments.</li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec16">Additional courses of interest </h2>

<ol>
<li> <a href="https://www.uio.no/studier/emner/matnat/math/STK4051/index-eng.html" target="_blank">STK4051 Computational Statistics</a></li>
<li> <a href="https://www.uio.no/studier/emner/matnat/math/STK4021/index-eng.html" target="_blank">STK4021 Applied Bayesian Analysis and Numerical Methods</a></li>
</ol>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>

<h2 id="___sec17">Best wishes to you all and thanks so much for your heroic efforts this semester </h2>

<p>
<br /><br /><center><p><img src="figures/Nebbdyr2.png" align="bottom" width=500></p></center><br /><br />

<p>

<!-- ------------------- end of main content --------------- -->


<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2019, Morten Hjorth-Jensen   Email morten.hjorth-jensen@fys.uio.no. Released under CC Attribution-NonCommercial 4.0 license
</center>


</body>
</html>
    

