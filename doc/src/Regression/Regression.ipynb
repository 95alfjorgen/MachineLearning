{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: Data Analysis and Machine Learning: Linear Regression and more Advanced Regression Analysis -->\n",
    "# Data Analysis and Machine Learning: Linear Regression and more Advanced Regression Analysis\n",
    "<!-- dom:AUTHOR: Morten Hjorth-Jensen at Department of Physics, University of Oslo & Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University -->\n",
    "<!-- Author: -->  \n",
    "**Morten Hjorth-Jensen**, Department of Physics, University of Oslo and Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University\n",
    "\n",
    "Date: **Jun 18, 2018**\n",
    "\n",
    "Copyright 1999-2018, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Regression analysis, overarching aims\n",
    "\n",
    "Regression modeling deals with the description of  the sampling distribution of a given random variable $y$ varies as function of another variable or a set of such variables $\\hat{x} =[x_0, x_1,\\dots, x_p]^T$. \n",
    "The first variable is called the **dependent**, the **outcome** or the **response** variable while the set of variables $\\hat{x}$ is called the independent variable, or the predictor variable or the explanatory variable. \n",
    "\n",
    "A regression model aims at finding a likelihood function $p(y\\vert \\hat{x})$, that is the conditional distribution for $y$ with a given $\\hat{x}$. The estimation of  $p(y\\vert \\hat{x})$ is made using a data set with \n",
    "* $n$ cases $i = 0, 1, 2, \\dots, n-1$ \n",
    "\n",
    "* Response (dependent or outcome) variable $y_i$ with $i = 0, 1, 2, \\dots, n-1$ \n",
    "\n",
    "* $p$ Explanatory (independent or predictor) variables $\\hat{x}_i=[x_{i0}, x_{i1}, \\dots, x_{ip}]$ with $i = 0, 1, 2, \\dots, n-1$   \n",
    "\n",
    " The goal of the regression analysis is to extract/exploit relationship between $y_i$ and $\\hat{x}_i$ in or to infer causal dependencies, approximations to the likelihood functions, functional relationships and to make predictions .\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## General linear models\n",
    "Before we proceed let us study a case from linear algebra where we aim at fitting a set of data $\\hat{y}=[y_0,y_1,\\dots,y_{n-1}]$. We could think of these data as a result of an experiment or a complicated numerical experiment. These data are functions of a series of variables $\\hat{x}=[x_0,x_1,\\dots,x_{n-1}]$, that is $y_i = y(x_i)$ with $i=0,1,2,\\dots,n-1$. The variables $x_i$ could represent physical quantities like time, temperature, position etc. We assume that $y(x)$ is a smooth function. \n",
    "\n",
    "Since obtaining these data points may not be trivial, we want to use these data to fit a function which can allow us to make predictions for values of $y$ which are not in the present set. The perhaps simplest approach is to assume we can parametrize our function in terms of a polynomial of degree $n-1$ with $n$ points, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y=y(x) \\rightarrow y(x_i)=\\tilde{y}_i+\\epsilon_i=\\sum_{j=0}^{n-1} \\beta_i x_i^j+\\epsilon_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\epsilon_i$ is the error in our approximation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Rewriting the fitting procedure as a linear algebra problem\n",
    "For every set of values $y_i,x_i$ we have thus the corresponding set of equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y_0&=\\beta_0+\\beta_1x_0^1+\\beta_2x_0^2+\\dots+\\beta_{n-1}x_0^{n-1}+\\epsilon_0\\\\\n",
    "y_1&=\\beta_0+\\beta_1x_1^1+\\beta_2x_1^2+\\dots+\\beta_{n-1}x_1^{n-1}+\\epsilon_1\\\\\n",
    "y_2&=\\beta_0+\\beta_1x_2^1+\\beta_2x_2^2+\\dots+\\beta_{n-1}x_2^{n-1}+\\epsilon_2\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{n-1}&=\\beta_0+\\beta_1x_{n-1}^1+\\beta_2x_{n-1}^2+\\dots+\\beta_1x_{n-1}^{n-1}+\\epsilon_{n-1}.\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewriting the fitting procedure as a linear algebra problem, follows\n",
    "Defining the vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\epsilon} = [\\epsilon_0,\\epsilon_1, \\epsilon_2,\\dots, \\epsilon_{n-1}]^T,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{X}=\n",
    "\\begin{bmatrix} \n",
    "1& x_{0}^1 &x_{0}^2& \\dots & \\dots &x_{0}^{n-1}\\\\\n",
    "1& x_{1}^1 &x_{1}^2& \\dots & \\dots &x_{1}^{n-1}\\\\\n",
    "1& x_{2}^1 &x_{2}^2& \\dots & \\dots &x_{2}^{n-1}\\\\                      \n",
    "\\dots& \\dots &\\dots& \\dots & \\dots &\\dots\\\\\n",
    "1& x_{n-1}^1 &x_{n-1}^2& \\dots & \\dots &x_{n-1}^{n-1}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can rewrite our equations as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\hat{X}\\hat{\\beta}+\\hat{\\epsilon}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalizing the fitting procedure as a linear algebra problem\n",
    "We are obviously not limited to the above polynomial. We could replace the various powers of $x$ with elements of Fourier series, that is, instead of $x_i^j$ we could have $\\cos{(j x_i)}$ or $\\sin{(j x_i)}$, or time series or other orthogonal functions.\n",
    "For every set of values $y_i,x_i$ we can then generalize the equations to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y_0&=\\beta_0x_{00}+\\beta_1x_{01}+\\beta_2x_{02}+\\dots+\\beta_{n-1}x_{0n-1}+\\epsilon_0\\\\\n",
    "y_1&=\\beta_0x_{10}+\\beta_1x_{11}+\\beta_2x_{12}+\\dots+\\beta_{n-1}x_{1n-1}+\\epsilon_1\\\\\n",
    "y_2&=\\beta_0x_{20}+\\beta_1x_{21}+\\beta_2x_{22}+\\dots+\\beta_{n-1}x_{2n-1}+\\epsilon_2\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{i}&=\\beta_0x_{i0}+\\beta_1x_{i1}+\\beta_2x_{i2}+\\dots+\\beta_{n-1}x_{in-1}+\\epsilon_i\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{n-1}&=\\beta_0x_{n-1,0}+\\beta_1x_{n-1,2}+\\beta_2x_{n-1,2}+\\dots+\\beta_1x_{n-1,n-1}+\\epsilon_{n-1}.\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalizing the fitting procedure as a linear algebra problem\n",
    "We redefine in turn the matrix $\\hat{X}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{X}=\n",
    "\\begin{bmatrix} \n",
    "x_{00}& x_{01} &x_{02}& \\dots & \\dots &x_{0,n-1}\\\\\n",
    "x_{10}& x_{11} &x_{12}& \\dots & \\dots &x_{1,n-1}\\\\\n",
    "x_{20}& x_{21} &x_{22}& \\dots & \\dots &x_{2,n-1}\\\\                      \n",
    "\\dots& \\dots &\\dots& \\dots & \\dots &\\dots\\\\\n",
    "x_{n-1,0}& x_{n-1,1} &x_{n-1,2}& \\dots & \\dots &x_{n-1,n-1}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and without loss of generality we rewrite again  our equations as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\hat{X}\\hat{\\beta}+\\hat{\\epsilon}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left-hand side of this equation forms know. Our error vector $\\hat{\\epsilon}$ and the parameter vector $\\hat{\\beta}$ are our unknow quantities. How can we obtain the optimal set of $\\beta_i$ values?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Optimizing our parameters\n",
    "We have defined the matrix $\\hat{X}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y_0&=\\beta_0x_{00}+\\beta_1x_{01}+\\beta_2x_{02}+\\dots+\\beta_{n-1}x_{0n-1}+\\epsilon_0\\\\\n",
    "y_1&=\\beta_0x_{10}+\\beta_1x_{11}+\\beta_2x_{12}+\\dots+\\beta_{n-1}x_{1n-1}+\\epsilon_1\\\\\n",
    "y_2&=\\beta_0x_{20}+\\beta_1x_{21}+\\beta_2x_{22}+\\dots+\\beta_{n-1}x_{2n-1}+\\epsilon_1\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{i}&=\\beta_0x_{i0}+\\beta_1x_{i1}+\\beta_2x_{i2}+\\dots+\\beta_{n-1}x_{in-1}+\\epsilon_1\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{n-1}&=\\beta_0x_{n-1,0}+\\beta_1x_{n-1,2}+\\beta_2x_{n-1,2}+\\dots+\\beta_1x_{n-1,n-1}+\\epsilon_{n-1}.\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing our parameters, more details\n",
    "We well use this matrix to define the approximation $\\hat{\\tilde{y}}$ via the unknown quantity $\\hat{\\beta}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\tilde{y}}= \\hat{X}\\hat{\\beta},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and in order to find the optimal parameters $\\beta_i$ instead of solving the above linear algebra problem, we define a function which gives a measure of the spread between the values $y_i$ (which represent hopefully the exact values) and the parametrized values $\\tilde{y}_i$, namely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Q(\\hat{\\beta})=\\sum_{i=0}^{n-1}\\left(y_i-\\tilde{y}_i\\right)^2=\\left(\\hat{y}-\\hat{\\tilde{y}}\\right)^T\\left(\\hat{y}-\\hat{\\tilde{y}}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or using the matrix $\\hat{X}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Q(\\hat{\\beta})=\\left(\\hat{y}-\\hat{X}\\hat{\\beta}\\right)^T\\left(\\hat{y}-\\hat{X}\\hat{\\beta}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretations and optimizing our parameters\n",
    "The function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Q(\\hat{\\beta})=\\left(\\hat{y}-\\hat{X}\\hat{\\beta}\\right)^T\\left(\\hat{y}-\\hat{X}\\hat{\\beta}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can be linked to the variance of the quantity $y_i$ if we interpret the latter as the mean value of for example a numerical  experiment. When linking below with the maximum likelihood approach below, we will indeed interpret $y_i$ as a mean value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y_{i}=\\langle y_i \\rangle = \\beta_0x_{i,0}+\\beta_1x_{i,1}+\\beta_2x_{i,2}+\\dots+\\beta_{n-1}x_{i,n-1}+\\epsilon_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\langle y_i \\rangle$ is the mean value. Keep in mind also that till now  we have treated $y_i$ as the exact value. Normally, the response (dependent or outcome) variable $y_i$ the outcome of a numerical experiment or another type of experiment and is thus only an approximation to the true value. It is then always accompanied by an error estimate, often limited to a statistical error estimate given by the standard deviation discussed earlier. In the discussion here we will treat $y_i$ as our exact value for the response variable.\n",
    "\n",
    "In order to find the parameters $\\beta_i$ we will then minimize the spread of $Q(\\hat{\\beta})$ by requiring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial Q(\\hat{\\beta})}{\\partial \\beta_j} = \\frac{\\partial }{\\partial \\beta_j}\\left[ \\sum_{i=0}^{n-1}\\left(y_i-\\beta_0x_{i,0}-\\beta_1x_{i,1}-\\beta_2x_{i,2}-\\dots-\\beta_{n-1}x_{i,n-1}\\right)^2\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which results in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial Q(\\hat{\\beta})}{\\partial \\beta_j} = -2\\left[ \\sum_{i=0}^{n-1}x_{ij}\\left(y_i-\\beta_0x_{i,0}-\\beta_1x_{i,1}-\\beta_2x_{i,2}-\\dots-\\beta_{n-1}x_{i,n-1}\\right)\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or in a matrix-vector form as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial Q(\\hat{\\beta})}{\\partial \\hat{\\beta}} = 0 = \\hat{X}^T\\left( \\hat{y}-\\hat{X}\\hat{\\beta}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretations and optimizing our parameters\n",
    "We can rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial Q(\\hat{\\beta})}{\\partial \\hat{\\beta}} = 0 = \\hat{X}^T\\left( \\hat{y}-\\hat{X}\\hat{\\beta}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{X}^T\\hat{y} = \\hat{X}^T\\hat{X}\\hat{\\beta},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if the matrix $\\hat{X}^T\\hat{X}$ is invertible we have the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\beta} =\\left(\\hat{X}^T\\hat{X}\\right)^{-1}\\hat{X}^T\\hat{y}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretations and optimizing our parameters\n",
    "The residuals $\\hat{\\epsilon}$ are in turn given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\epsilon} = \\hat{y}-\\hat{\\tilde{y}} = \\hat{y}-\\hat{X}\\hat{\\beta},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{X}^T\\left( \\hat{y}-\\hat{X}\\hat{\\beta}\\right)= 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{X}^T\\hat{\\epsilon}=\\hat{X}^T\\left( \\hat{y}-\\hat{X}\\hat{\\beta}\\right)= 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meaning that the solution for $\\hat{\\beta}$ is the one which minimizes the residuals.  Later we will link this with the maximum likelihood approach.\n",
    "\n",
    "\n",
    "\n",
    "## Simple regression model\n",
    "We are now ready to write our first program which aims at solving the above linear regression equations. We start with data we have produced ourselves, in this case normally distributed random numbers along the $x$-axis. These numbers define then the value of a function $y(x)=4+3x+N(0,1)$. Thereafter we order the $x$ values and employ our linear regression algorithm to set up the best fit. Here we find it useful to use the numpy function $c\\_$ arrays where arrays are stacked along their last axis after being upgraded to at least two dimensions with ones post-pended to the shape. The following examples help in understanding what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.c_[np.array([1,2,3]), np.array([4,5,6])])\n",
    "print(np.c_[np.array([[1,2,3]]), 0, 0, np.array([[4,5,6]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHx9JREFUeJzt3XuYXHWd5/H3J1fsBIF0glyTgLIo\nKorTXkYdxIRVBhnR1ceBJwgBtJEWF1dmBcwzIzsziPu4O+qIQCJykxZFRlnGRx0j4rIiRJuL3JEA\nSUi45QJCDCQk+e4fv1P2SaW6+3R3VZ2q7s/refrpqnNOnfOtk0p9+3dXRGBmZjaUCWUHYGZm7cEJ\nw8zMCnHCMDOzQpwwzMysECcMMzMrxAnDzMwKccKwliHpryQ9VHYcY4Gk2ZI2SppYdiw2djhhWNNJ\nWiHpyOrtEfH/IuLgMmKqJuk8SS9nX7rPSfqNpL8sO66iImJVREyPiG1lx2JjhxOGjXuSJg2w6/sR\nMR2YCdwE/KDJ1zdrKU4Y1jIkHSFpde75Ckl/J+luSX+U9H1Ju+T2HyPprlwJ4NDcvnMkPSLpBUn3\nS/pwbt9CSbdI+qqk9cB5g8UVEVuBXmBfSbMKXv8tku7Mrv+DLPZ/zr9PSWdLegq4vMD5zpa0Jjvf\nQ5LmZ9vfJqlP0vOSnpb0L9n2uZKikowk7SPpBkkbJC2X9Mncuc+TdK2kq7Lz3yepq/A/nI0bThjW\n6j4GHAUcABwKLASQdBhwGXAa0AksBm6QNDV73SPAXwG7Af8DuFrS3rnzvh14FHgVcP5gAUiaApwI\nrAeeHer62fE/Aq4AZgDXAB+uOu1e2b45QPcQ5zsYOAN4a0TsCrwfWJGd5+vA1yPilcCrgWsHeBvf\nA1YD+wAfBb4kaV5u/wezY3YHbgAuHOye2PjkhGGt7l8j4omI2AD8O/DmbHs3sDgilkXEtoi4EtgM\nvAMgIn6QvW57RHwfeBh4W+68T0TENyJia0S8OMC1PybpOeBF4JPAR7PSxlDXfwcwKYv95Yj4IfDb\nqnNvB74YEZuz6w92vm3AVOAQSZMjYkVEPJKd52XgNZJmRsTGiLit+k1I2h94F3B2RLwUEXcBl5KS\nYMWvI+InWZvHd4A3DXBPbBxzwrBW91Tu8SZgevZ4DnBWVn3zXPbFvj/pL2gknZir3nkOeAOpLaLi\n8QLXvjYidieVQu4F/iK3b7Dr7wOsiR1n9qy+3tqIeKnI+SJiOfBZUtXZM5K+J2mf7HWnAv8JeFDS\n7yQdU+N97ANsiIgXcttWAvvmnlff513ctmLVnDCsXT0OnB8Ru+d+OiLiGklzgG+RqnE6sy/9ewHl\nXl94muaIWEcqAZyXq9Ya8PrAk6T2jvz19q8+bdH3k8Xw3Yh4NymxBPA/s+0PR8TxwJ7ZtuskTas6\n9xPADEm75rbNBtYUvQdm4IRh5ZksaZfcz3D/mv0W8ClJb1cyTdIHsi/FaaQv1bUAkk4mlTBGLCIe\nAv4D+HyB699KqkY6Q9IkSceyY3XYsN6PpIMlzcvaZ14iVZFtz97bCZJmRcR24LnsXNurYn8c+A1w\nQXavDyWVTK4ezT2x8ccJw8ryE9IXX+XnvOG8OCL6SO0KF5IaopeTNYhHxP3A/yZ9cT8NvBG4pQ4x\nf4XUQL3nENffAvwX0pfyc8AJwI9JbRLDfj+k9osvA+tIVUd7Audm+44C7pO0kdQAftwAbTLHA3NJ\npY0fkdpPfjHM92/jnLyAklnjSVoGXBIRl5cdi9lIuYRh1gCS3iNpr6xK6iRSl+CflR2X2Wi4F4RZ\nYxxMGhMxjTTe46MR8WS5IZmNjqukzMysEFdJmZlZIW1VJTVz5syYO3du2WGYmbWV22+/fV1EzBr6\nyMG1VcKYO3cufX19ZYdhZtZWJK2sx3lcJWVmZoU4YZiZWSFOGGZmVogThpmZFeKEYWZmhThhmJlZ\nIU4YZmZWiBOGmZkV4oRhZmaFOGGYmVkhDU8Yki6T9Iyke2vsO0tSSJrZ6DjMzGx0mlHCuIK0jOQO\nJO0PvA9Y1YQYzMxslBqeMCLiZmBDjV1fBT4PeEEOM7M2UEobhqRjgTUR8fsCx3ZL6pPUt3bt2iZE\nZ2ZmtTQ9YUjqAL4A/EOR4yNiSUR0RUTXrFmjns7dzMxGqIwSxquBA4DfS1oB7AfcIWmvEmIxM7OC\nmr6AUkTcA+xZeZ4lja6IWNfsWMzMrLhmdKu9BrgVOFjSakmnNvqaZmZWfw0vYUTE8UPsn9voGMzM\nbPQ80tvMzApxwjAzs0KcMMzMrBAnDDMzK8QJw8zMCnHCMDOzQpwwzMysECcMMzMrxAnDzMwKccIw\nM7NCnDDMzKwQJwwzMyvECcPMzApxwjAzs0KcMMzMrBAnDDMzK8QJw8zMCnHCMDOzQpwwzMysECcM\nMzMrpOEJQ9Jlkp6RdG9u21ckPSjpbkk/krR7o+MwM7PRaUYJ4wrgqKptS4E3RMShwB+Ac5sQh5mZ\njULDE0ZE3AxsqNr284jYmj29Ddiv0XGYmdnotEIbxinATwfaKalbUp+kvrVr1zYxLDMzyys1YUha\nBGwFegc6JiKWRERXRHTNmjWrecGZmdkOJpV1YUkLgWOA+RERZcVhZmbFlJIwJB0FfB54T0RsKiMG\nMzMbnmZ0q70GuBU4WNJqSacCFwK7Aksl3SXpkkbHYWZmo9PwEkZEHF9j87cbfV0zM6uvVuglZWZm\nbcAJw8zMCnHCMDOzQpwwzMysECcMMzMrxAnDzMwKccIwM7NCnDDMzKwQJwwzMyvECcPMzApxwjAz\ns0KcMMzMrBAnDDMzK8QJw8zMCnHCMDOzQpwwzMysECcMMzMrxAnDzMwKccIwM7NCnDDMzKyQhicM\nSZdJekbSvbltMyQtlfRw9nuPRsdhZjYu9PbC3LkwYUL63dtbt1M3o4RxBXBU1bZzgBsj4iDgxuy5\nmZmNRm8vdHfDypUQkX53dzMTZtTj9A1PGBFxM7ChavOxwJXZ4yuBDzU6DjOzMW/RIti0acdtmzax\nD+xbj9NPqsdJRuBVEfFk9vgp4FUDHSipG+gGmD17dhNCMzNrM489BjfemEoUNUyGKfW4TOmN3hER\nQAyyf0lEdEVE16xZs5oYmZlZiSptEVJqj5DSz8yZcNFF8N3vwic+AQccAAceCJ/8ZDquhpdhSz1C\nKquE8bSkvSPiSUl7A8+UFIeZWeuptEVUqpci9zf1+vXw6U+nx7vvDkccAWedBfPmwZ137vg6gI4O\nnti0aU09wiorYdwAnAR8Ofv9f0qKw8ysXD09sHgxbN+enk+bBlOn7twWUW2vvWD1apg4sX/bIYek\n34sWwapVMHs2nH8+6044obodeUQUMWBtUF1IugY4ApgJPA18EbgeuBaYDawEPhYRQ76hrq6u6Ovr\na1ywZmbN1NMDF188stdK/UlmyEN1e0R0jexC/RpewoiI4wfYNb/R1zYza0nbt8Pdd8Mll4z8HCV0\nAiqrSsrMbPyIgIcfhl/+MvVmuumm1BYxUlOmwPnn1y++gpwwzMwaYc2alBxuvDElitWr0/b99oNj\njoH58+Hkk2Hbttqv7+yE6dNTV1mpv+G7sxO+/nVYsKA57yPHCcPMrKjeXjjzzP7SQf7Le/36VHKo\nlCL+8If+Y+bNSz/z58NrXpMSAMCtt9Zuw5gwobSkMJiGN3rXkxu9zaypentTj6Pqv/LzpNSesGpV\n2j99Ohx+eEoO8+bBoYcOOD4CqN1LavHiuiaLejV6O2GYmdVy5JGppFDE1KkpscyfD299K0ye3NjY\nhqltekmZmbWdnp7iyQJgyxb4+79vXDwtovSpQczMmqq3N02vkZ9qo7c3VSfdfz984xvD7+46Tua5\ncwnDzMaP3l445ZRUIqhYvx4+/vFUqnj++eGfc/LkUrq4lsElDDMbW3p6YNKkVHqYNCk9rzjnnB2T\nRUUEbN0K3/oWPProjtNtDKazEy6/vOV6MzWKE4aZtaf8ynIzZ/ZXM118cf/Yhm3b0vNDD00/lbEQ\ntbz4Yv/sr93dAx83Zw5cfXVKMuvWjZtkAU4YZtZuKm0QJ5zQv7Lc+vWDj5y+5x541avS7K4DybdD\nXHQRnH56f0lj4sT0PAJWrBhXSSLPCcPM2kdl2u+RTKuxdClceGGaVqNarXaIiy5K1VSV6qqLLhpZ\nzGOIE4aZtY8vfGHoab9rqZQUFiyAyy5LbQ8V46wdYjTcS8rMWlcEPPJI/3Qbq1aN7Dz5NokFC5wc\nRsglDDNrvnyD9dy56XnFE0+kRuVTTkn7DjoITjsNfv3rNG3GcFTaHlydVBdOGGbWWLXWps43WK9c\nCaeeCu97H7zudbDvvmlcxPXXQ1cXfPOb8OCDqYfT4sXQ0TH49To7+3sxue2hrlwlZWaNM9ja1Hmb\nN8MvfgHvf39KHvPmwZvfvPOkfZWqpMoSpDNmpOcbNvx5OVJXNzWOJx80s8aZOzeVIIoYxpKjNjz1\nmnzQVVJmNjIDtUNs2wZ33AFf+UrxZAHjZj6mduYqKTMbWmVdiFWr0hf70UfDlVf2VzWtXJlWj/va\n11KvpmefTdsnTUrtCEPp6Bg38zG1s1JLGJL+m6T7JN0r6RpJu5QZj5nV0NOTGqHzjdSXXLLzeIiX\nX4Y774QPfSg1Oq9ZA1dcUayReskStz20gdJKGJL2Bf4rcEhEvCjpWuA44IqyYjKzKr29KTlUt3UO\n1Pa5fXsaGFeRb6RuobWpbWTKrpKaBLxC0stAB/BEyfGYGcALL8DNN/fPn1RUrXYID5QbM0pLGBGx\nRtL/AlYBLwI/j4ifVx8nqRvoBpjtRjGzxnjpJbj11v4R1b/9bf+MrwOpXuPa7RBjXmltGJL2AI4F\nDgD2AaZJOqH6uIhYEhFdEdE1a9asZodp1n6qV5TLrypXsXVrSgoXXJDWrt5jjzT24UtfStVKZ5+d\nEsf++9e+hgSf+lSa6ltKv90OMeaVWSV1JPBYRKwFkPRD4J3A1SXGZNbeaq0oB2l214UL4Wc/S6vK\n/epX/avLvfGN6ct/3jw4/HDYbbf+111wwY4D76A/WXgE9bhTZsJYBbxDUgepSmo+4FF5ZsPR2wtn\nntk/3feECQMPftu6NfVeevWr4W//FubPh/e+F/bcc+DzV4+s9mjqca3MNoxlkq4D7gC2AncCS8qK\nx6wt9PSk+ZQGSgpDjZSWYPny4V3TjdaWKXUcRkR8MSJeGxFviIiPR8TmMuMxaynVI6mPPDItNzqa\n6TPcccRGYciEIWmppDc1IxizcS8/s2v1jK433ji6c9daVc5sGIqUMM4Gvibpckl7Nzogs3GlukdT\nJUmMVvUsr15VzupgyIQREXdExHuBHwM/k/RFSa9ofGhmY1ylR9NI1qcezJQpcNVVqWRS+Vm3zsnC\nRq1QG4YkAQ8BFwOfAR6W9PFGBmbW9vJtEDNnwq677jgu4swzd+7+OlqdnWlqDicHa4AibRi3AGuA\nrwL7AguBI4C3SXKvJrOKgaqXIlIpYuPG/mPXrx9+yUJKXWHz1U3TpvWvLueShDVYkW613cD9sfNK\nS5+R9EADYjJrP729aWBckam8R8KD5awFFGnDuK9Gsqj4QJ3jMWsf+SqnE0+sf7KYODH9njMHvvMd\nJwsr3agG7kXEo/UKxKytFF2reiidnel3pXrKU35bC/MSrWbVenrSSnFS+t3T079v2zbo64Mzzth5\nAaHhmjw5JYd169wGYW2h7PUwzFpHby+cdhr86U/927ZtS6Or774bZs1Kk/Y999zIzj91KmzOJjNw\nScLakEsYNn7V6tWUTxZ5t9wCd90FH/kIfPe7sN9+xa/T2Zl6Mr30kksS1tZcwrDxobe3f5nQiROH\nXhyolsce63+8ffvO035PmZLGWmzY4FldbUxywrCxr7qBeiTJotJjqcLTfts45CopG1uqZ3jt7YVz\nzx19A3V3987bFiyAFStSaWPFCicLG/OcMKx9VSeHnp70xZ6f4fXEE+Hxx0d+jQkT4PTTPQbCDCcM\nayfVczOdfPKOyeHii3cuSWzfnhq0h2vOnNRQvW2bk4VZxm0Y1roqDdWrVsGMGWkN6pdfTvuGMw9T\nBHR0DF0t5a6uZoNyCcNaQ3UX1+nT09Tf+cn7KsliuObMgSVL0m/YccoNT9xnVphLGFaOfDdXaeep\nNQYaDzGU6nN1dPT3XnIyMBsVlzCs8QZrnIaRz8NUraMjzeg6Z05KHJWShROFWV2UWsKQtDtwKfAG\nIIBTIuLWMmOyOuvtTY3TleqkSuN0PXignFlTlV0l9XXgZxHxUUlTgI6S47F6O/PMkbc9VHOCMCtV\naVVSknYDDge+DRARWyJihLO6WSkqVU2VWV2l/sFyEfDgg6Nbr3rChNRzqVK9dNllqWHaA+XMSlFm\nG8YBwFrgckl3SrpU0rTqgyR1S+qT1Ld27drmR2nJUO0Qlek2Vq6Ek05K3WBf97qRX6+zE666ygnC\nrIWUmTAmAW8BLo6Iw4A/AedUHxQRSyKiKyK6Zs2a1ewYx7d8CSK/PvVAg+Qqtm2DLVtg8WLYY4+B\nz1/p3lqrm6u7uJq1nDLbMFYDqyNiWfb8OmokDCtJ9YR9w/Xii+n106alEkf1hH9TpqQqJicFs7ZR\nWgkjIp4CHpd0cLZpPnB/WfGMS7Um6qtYtGh0E/bNnp1+L1gAV17ZvxQppMdOFmZtp+xeUp8BerMe\nUo8CJ5ccz/hRXYJYuTI9X748/fVfaZsYicpguQoPmjMbE0oduBcRd2XtE4dGxIci4tky4xlzhluC\n2LQJzjsPvvCFtN70UKZPrz3dhgfLmY1JZZcwrFF6euCSS/pHUVdKEM88k8YyDFSCkOCpp2Dp0sHb\nMCZNSud3YjAbN5ww2l1+RtfKYDbYMVlUbNoEn/tcejxhQuquWm32bNhzzx1XlFu5csfjPaur2bik\nqNc8Pk3Q1dUVfX19ZYfROmr1ZHrFK9Jf/y+8MPDr7r8f7rhj59d2dLg6yWwMknR7RHSN9jyefLAd\n9PT0j6SeNCk9h9rtEC++OHiymDMnDahbsKB/ym9P1GdmBbhKqhXlq5k6Onac6nvbtjRorq9v+D2Z\nJPdeMrMRc8JoBb29aZK+WvMuDbQuxO9+l3oy1ZrYr7MzlTTypQ8pTf3tBGFmI+QqqTJUr0194okj\nm6Tv8stTCSSvoyM1SFdXN33nO16b2sxGxSWMZhlohbmRzuY6ceKOPZnyvaQq212aMLM6csJohure\nTPXomdbdnX67HcLMmsRVUvXQ25uqlqT0M3PmjqOqzz13dPMyTZiQfiCVLE4/3dVLZtZ0LmGMVvUS\npJCqmRYuhOuug7Vr4fHHR37+OXO8spyZtQSXMIrq6Ul/3VdKEZWSxEBLkG7dCtdfn/a98pWDn3vK\nlDQNeEVnZ/+6EF44yMxahBNGET09aexD9VQa69cP3mgtwbJlqfqoujeTlH5Xlh7duDElCC8eZGYt\nygmjlupZXhcvHtl58mtC1Orm6hKEmbWR8d2GMdDEfdXrRIzElCkeVW1mY8r4SRjVyeHoo9NKcPnE\ncOqp6fHmzcM7d2U1uUr1lGdzNbMxaGwnjIEGy61cWXv67+EmCkglCScHMxsHxk4bRvVYCAlOOKG/\nSqk6OQx38Ny0af1jISq8NrWZjSNjo4RRayzESNWauK+jIzV8OzGY2TjWfiWMWutUL1o0smRR6dpa\nMdDEfV4nwsys/BX3JE0E+oA1EXHMYMd2HXhg9D399I5//U+ZAlu2DP/CHR1w0knwk5/UnrjPzGyM\nqNeKe61QJXUm8AAwxHBoYPXqnUsSI0kWnm7DzGzYSq2SkrQf8AHg0kIvGKzaafLkoV9/+ukeLGdm\nNkJlt2F8Dfg8sH2gAyR1S+qT1BfVbQ4Vc+akxYQq4yGqVeZm8gyvZmYjVlrCkHQM8ExE3D7YcRGx\nJCK6IqJLc+fWXmGuUr20bl3/fEz5H8/NZGY2amWWMN4FfFDSCuB7wDxJVw/6ihkz3IPJzKwkpfeS\nApB0BPB3Q/aS6uqKvr6+5gRlZjZG1KuXVNltGGZm1iZaoVstEfEr4Fclh2FmZoNwCcPMzApxwjAz\ns0KcMMzMrBAnDDMzK8QJw8zMCnHCMDOzQpwwzMysECcMMzMrxAnDzMwKccIwM7NCnDDMzKwQJwwz\nMyvECcPMzApxwjAzs0KcMMzMrBAnDDMzK8QJw8zMCnHCMDOzQpwwzMysECcMMzMrpLSEIWl/STdJ\nul/SfZLOLCsWMzMb2qQSr70VOCsi7pC0K3C7pKURcX+JMZmZ2QBKK2FExJMRcUf2+AXgAWDfsuIx\nM7PBtUQbhqS5wGHAshr7uiX1Sepbu3Zts0MzM7NM6QlD0nTg34DPRsTz1fsjYklEdEVE16xZs5of\noJmZASUnDEmTScmiNyJ+WGYsZmY2uDJ7SQn4NvBARPxLWXGYmVkxZZYw3gV8HJgn6a7s5+gS4zEz\ns0GU1q02In4NqKzrm5nZ8JTe6G1mZu3BCcPMzApxwjAzs0KcMMzMrBAnDDMzK8QJw8zMCnHCMDOz\nQpwwzMysECcMMzMrxAnDzMwKccIwM7NCnDDMzKwQJwwzMyvECcPMzApxwjAzs0KcMMzMrBAnDDMz\nK8QJw8zMCnHCMDOzQpwwzMyskFIThqSjJD0kabmkc8qMxczMBldawpA0Efgm8NfAIcDxkg4pKx4z\nMxtcmSWMtwHLI+LRiNgCfA84tsR4zMxsEJNKvPa+wOO556uBt1cfJKkb6M6ebpZ0bxNiG62ZwLqy\ngyjAcdZPO8QIjrPe2iXOg+txkjITRiERsQRYAiCpLyK6Sg5pSI6zvtohznaIERxnvbVTnPU4T5lV\nUmuA/XPP98u2mZlZCyozYfwOOEjSAZKmAMcBN5QYj5mZDaK0KqmI2CrpDOA/gInAZRFx3xAvW9L4\nyOrCcdZXO8TZDjGC46y3cRWnIqIe5zEzszHOI73NzKwQJwwzMyukZRLGUNOESJoq6fvZ/mWS5ub2\nnZttf0jS+0uM8XOS7pd0t6QbJc3J7dsm6a7sp6GN+wXiXChpbS6eT+T2nSTp4eznpJLj/Gouxj9I\nei63ryn3U9Jlkp4ZaPyPkn/N3sPdkt6S29fMezlUnAuy+O6R9BtJb8rtW5Ftv6te3S9HEecRkv6Y\n+7f9h9y+pk0lVCDO/56L8d7s8zgj29eU+ylpf0k3Zd8590k6s8Yx9f18RkTpP6RG70eAA4EpwO+B\nQ6qO6QEuyR4fB3w/e3xIdvxU4IDsPBNLivG9QEf2+PRKjNnzjS10LxcCF9Z47Qzg0ez3HtnjPcqK\ns+r4z5A6RjT7fh4OvAW4d4D9RwM/BQS8A1jW7HtZMM53Vq5Pmo5nWW7fCmBmi9zPI4Afj/bz0ug4\nq479G+CXzb6fwN7AW7LHuwJ/qPF/va6fz1YpYRSZJuRY4Mrs8XXAfEnKtn8vIjZHxGPA8ux8TY8x\nIm6KiE3Z09tIY0uabTRTrrwfWBoRGyLiWWApcFSLxHk8cE2DYhlQRNwMbBjkkGOBqyK5Ddhd0t40\n914OGWdE/CaLA8r7bBa5nwNp6lRCw4yzrM/mkxFxR/b4BeAB0gwaeXX9fLZKwqg1TUj1G//zMRGx\nFfgj0Fnwtc2KMe9UUmav2EVSn6TbJH2oAfFVFI3zI1kR9TpJlQGUzbqXw7pWVrV3APDL3OZm3c+h\nDPQ+mnkvh6v6sxnAzyXdrjQVT9n+UtLvJf1U0uuzbS15PyV1kL5o/y23uen3U6mK/jBgWdWuun4+\nW35qkHYk6QSgC3hPbvOciFgj6UDgl5LuiYhHyomQfweuiYjNkk4jldzmlRRLEccB10XEtty2Vrqf\nbUPSe0kJ4925ze/O7uWewFJJD2Z/YZfhDtK/7UZJRwPXAweVFEsRfwPcEhH50khT76ek6aSE9dmI\neL5R14HWKWEUmSbkz8dImgTsBqwv+NpmxYikI4FFwAcjYnNle0SsyX4/CvyK9NdAIwwZZ0Ssz8V2\nKfAXRV/bzDhzjqOqyN/E+zmUgd5Hy019I+lQ0r/3sRGxvrI9dy+fAX5EY6p0C4mI5yNiY/b4J8Bk\nSTNpwfuZGeyz2fD7KWkyKVn0RsQPaxxS389noxtmCjbeTCI1uhxAf4PW66uO+TQ7Nnpfmz1+PTs2\nej9KYxq9i8R4GKlh7qCq7XsAU7PHM4GHaVCDXcE49849/jBwW/Q3hD2WxbtH9nhGWXFmx72W1Iio\nMu5ndo25DNxI+wF2bFT8bbPvZcE4Z5Pa995ZtX0asGvu8W+Ao0qMc6/KvzXpi3ZVdm8LfV6aFWe2\nfzdSO8e0Mu5ndl+uAr42yDF1/Xw27GaP4M0fTWrlfwRYlG37R9Jf6gC7AD/IPvS/BQ7MvXZR9rqH\ngL8uMcZfAE8Dd2U/N2Tb3wnck33I7wFOLfleXgDcl8VzE/Da3GtPye7xcuDkMuPMnp8HfLnqdU27\nn6S/Hp8EXibV854KfAr4VLZfpIXAHsli6SrpXg4V56XAs7nPZl+2/cDsPv4++0wsKjnOM3KfzdvI\nJbhan5ey4syOWUjqcJN/XdPuJ6laMYC7c/+uRzfy8+mpQczMrJBWacMwM7MW54RhZmaFOGGYmVkh\nThhmZlaIE4aZmRXihGFmZoU4YZiZWSFOGGajkK1H8J+zx/8s6Rtlx2TWKJ580Gx0vgj8YzbR3GHA\nB0uOx6xhPNLbbJQk/V9gOnBEpHUJzMYkV0mZjYKkN5JWPtviZGFjnROG2QhlK5f1klY12yipYSvq\nmbUCJwyzEchWWvshcFZEPAD8E6k9w2zMchuGmZkV4hKGmZkV4oRhZmaFOGGYmVkhThhmZlaIE4aZ\nmRXihGFmZoU4YZiZWSH/H/ihL8Cej10uAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10620af98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Importing various packages\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = 2*np.random.rand(100,1)\n",
    "y = 4+3*x+0.01*np.random.randn(100,1)\n",
    "\n",
    "xb = np.c_[np.ones((100,1)), x]\n",
    "theta = np.linalg.inv(xb.T.dot(xb)).dot(xb.T).dot(y)\n",
    "xnew = np.array([[0],[2]])\n",
    "xbnew = np.c_[np.ones((2,1)), xnew]\n",
    "ypredict = xbnew.dot(theta)\n",
    "\n",
    "plt.plot(xnew, ypredict, \"r-\")\n",
    "plt.plot(x, y ,'ro')\n",
    "plt.axis([0,2.0,0, 15.0])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.title(r'Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, as expected, a linear fit gives a seemingly (from the graph) good representation of the data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Simple regression model, now using **scikit-learn**\n",
    "\n",
    "\n",
    "We can repeat the above algorithm using **scikit-learn** as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106951860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing various packages\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = 2*np.random.rand(100,1)\n",
    "y = 4+3*x+np.random.randn(100,1)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x,y)\n",
    "xnew = np.array([[0],[2]])\n",
    "ypredict = linreg.predict(xnew)\n",
    "\n",
    "plt.plot(xnew, ypredict, \"r-\")\n",
    "plt.plot(x, y ,'ro')\n",
    "plt.axis([0,2.0,0, 15.0])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.title(r'Random numbers ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations and the quality of our results\n",
    "In order to test the quality of our fit, there are several measures which can be implemented. One is the so-called\n",
    "correlation function defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathrm{Corr}(X,Y) = \\frac{\\sum_{i=1}^n(x_i-\\overline{x})(y_i-\\overline{y})}{\\sqrt{\\sum_{i=1}^n(x_i-\\overline{x})^2}\\sqrt{\\sum_{i=1}^n(y_i-\\overline{y})^2} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another quantity is the autocorrelation function we discussed in our chapter on statistical analysis. \n",
    "Let us now try to assess the quality of our fit by studying various measures.\n",
    "\n",
    "## Estimate of the error\n",
    "\n",
    "## The $\\chi^2$ function\n",
    "\n",
    "Normally, the response (dependent or outcome) variable $y_i$ the outcome of a numerical experiment or another type of experiment and is thus only an approximation to the true value. It is then always accompanied by an error estimate, often limited to a statistical error estimate given by the standard deviation discussed earlier. In the discussion here we will treat $y_i$ as our exact value for the response variable.\n",
    "\n",
    "Introducing the standard deviation $\\sigma_i$ for each measurement $y_i$, we define now the $\\chi^2$ function as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\chi^2(\\hat{\\beta})=\\sum_{i=0}^{n-1}\\frac{\\left(y_i-\\tilde{y}_i\\right)^2}{\\sigma_i^2}=\\left(\\hat{y}-\\hat{\\tilde{y}}\\right)^T\\frac{1}{\\hat{\\Sigma^2}}\\left(\\hat{y}-\\hat{\\tilde{y}}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the matrix $\\hat{\\Sigma}$ is a diagonal matrix with $\\sigma_i$ as matrix elements.\n",
    "\n",
    "\n",
    "\n",
    "## The $\\chi^2$ function\n",
    "\n",
    "In order to find the parameters $\\beta_i$ we will then minimize the spread of $\\chi^2(\\hat{\\beta})$ by requiring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\hat{\\beta})}{\\partial \\beta_j} = \\frac{\\partial }{\\partial \\beta_j}\\left[ \\sum_{i=0}^{n-1}\\left(\\frac{y_i-\\beta_0x_{i,0}-\\beta_1x_{i,1}-\\beta_2x_{i,2}-\\dots-\\beta_{n-1}x_{i,n-1}}{\\sigma_i}\\right)^2\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which results in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\hat{\\beta})}{\\partial \\beta_j} = -2\\left[ \\sum_{i=0}^{n-1}\\frac{x_{ij}}{\\sigma_i}\\left(\\frac{y_i-\\beta_0x_{i,0}-\\beta_1x_{i,1}-\\beta_2x_{i,2}-\\dots-\\beta_{n-1}x_{i,n-1}}{\\sigma_i}\\right)\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or in a matrix-vector form as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\hat{\\beta})}{\\partial \\hat{\\beta}} = 0 = \\hat{A}^T\\left( \\hat{b}-\\hat{A}\\hat{\\beta}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we have defined the matrix $\\hat{A} =\\hat{X}/\\hat{\\Sigma}$ with matrix elements $a_{ij} = x_{ij}/\\sigma_i$ and the vector $\\hat{b}$ with elements $b_i = y_i/\\sigma_i$.\n",
    "\n",
    "\n",
    "\n",
    "## The $\\chi^2$ function\n",
    "\n",
    "We can rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\hat{\\beta})}{\\partial \\hat{\\beta}} = 0 = \\hat{A}^T\\left( \\hat{b}-\\hat{A}\\hat{\\beta}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{A}^T\\hat{b} = \\hat{A}^T\\hat{A}\\hat{\\beta},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if the matrix $\\hat{A}^T\\hat{A}$ is invertible we have the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\beta} =\\left(\\hat{A}^T\\hat{A}\\right)^{-1}\\hat{A}^T\\hat{b}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $\\chi^2$ function\n",
    "\n",
    "If we then introduce the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{H} =  \\hat{A}^T\\hat{A},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have then the following expression for the parameters $\\beta_j$ (the matrix elements of $\\hat{H}$ are $h_{ij}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\beta_j = \\sum_{k=0}^{p-1}h_{jk}\\sum_{i=0}^{n-1}\\frac{y_i}{\\sigma_i}\\frac{x_{ik}}{\\sigma_i} = \\sum_{k=0}^{p-1}h_{jk}\\sum_{i=0}^{n-1}b_ia_{ik}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We state without proof the expression for the uncertainty  in the parameters $\\beta_j$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2(\\beta_j) = \\sum_{i=0}^{n-1}\\sigma_i^2\\left( \\frac{\\partial \\beta_j}{\\partial y_i}\\right)^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2(\\beta_j) = \\left(\\sum_{k=0}^{p-1}h_{jk}\\sum_{i=0}^{n-1}a_{ik}\\right)\\left(\\sum_{l=0}^{p-1}h_{jl}\\sum_{m=0}^{n-1}a_{ml}\\right) = h_{jj}!\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $\\chi^2$ function\n",
    "The first step here is to approximate the function $y$ with a first-order polynomial, that is we write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y=y(x) \\rightarrow y(x_i) \\approx \\beta_0+\\beta_1 x_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By computing the derivatives of $\\chi^2$ with respect to $\\beta_0$ and $\\beta_1$ show that these are given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\hat{\\beta})}{\\partial \\beta_0} = -2\\left[ \\sum_{i=0}^{1}\\left(\\frac{y_i-\\beta_0-\\beta_1x_{i}}{\\sigma_i^2}\\right)\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\hat{\\beta})}{\\partial \\beta_0} = -2\\left[ \\sum_{i=0}^{1}x_i\\left(\\frac{y_i-\\beta_0-\\beta_1x_{i}}{\\sigma_i^2}\\right)\\right]=0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $\\chi^2$ function\n",
    "\n",
    "We define then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma =  \\sum_{i=0}^{1}\\frac{1}{\\sigma_i^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "1\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "2\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "3\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma_{xy} = \\sum_{i=0}^{1}\\frac{y_ix_{i}}{\\sigma_i^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and show that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "5\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\beta_1 = \\frac{\\gamma_{xy}\\gamma-\\gamma_x\\gamma_y}{\\gamma\\gamma_{xx}-\\gamma_x^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSM suffers often from both being underdetermined and overdetermined in the unknown coefficients $\\beta_i$.  A better approach is to use the Singular Value Decomposition (SVD) method discussed below.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Simple regression model with gradient descent\n",
    "Add info about the equations, play around with different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.00119617]\n",
      " [2.99892839]]\n",
      "[[4.00119617]\n",
      " [2.99892839]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzPLxAnDzMwyccIwM7NM/j/lm2Oc1ii4WgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107238b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing various packages\n",
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = 2*np.random.rand(100,1)\n",
    "y = 4+3*x+0.01*np.random.randn(100,1)\n",
    "\n",
    "xb = np.c_[np.ones((100,1)), x]\n",
    "theta_linreg = np.linalg.inv(xb.T.dot(xb)).dot(xb.T).dot(y)\n",
    "print(theta_linreg)\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "eta = 0.1\n",
    "Niterations = 1000\n",
    "m = 100\n",
    "\n",
    "for iter in range(Niterations):\n",
    "    gradients = 2.0/m*xb.T.dot(xb.dot(theta)-y)\n",
    "    theta -= eta*gradients\n",
    "\n",
    "print(theta)\n",
    "xnew = np.array([[0],[2]])\n",
    "xbnew = np.c_[np.ones((2,1)), xnew]\n",
    "ypredict = xbnew.dot(theta)\n",
    "ypredict2 = xbnew.dot(theta_linreg)\n",
    "plt.plot(xnew, ypredict, \"r-\")\n",
    "plt.plot(xnew, ypredict2, \"b-\")\n",
    "plt.plot(x, y ,'ro')\n",
    "plt.axis([0,2.0,0, 15.0])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.title(r'Random numbers ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple regression model with stochastic gradient descent\n",
    "Add info about the equations, play around with different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing various packages\n",
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "x = 2*np.random.rand(100,1)\n",
    "y = 4+3*x+np.random.randn(100,1)\n",
    "\n",
    "xb = np.c_[np.ones((100,1)), x]\n",
    "theta_linreg = np.linalg.inv(xb.T.dot(xb)).dot(xb.T).dot(y)\n",
    "print(theta_linreg)\n",
    "sgdreg = SGDRegressor(n_iter = 50, penalty=None, eta0=0.1)\n",
    "sgdreg.fit(x,y.ravel())\n",
    "print(sgdreg.intercept_, sgdreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing various packages\n",
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = 100\n",
    "x = 2*np.random.rand(m,1)+4.\n",
    "y = 4+3*x*x+ +x-np.random.randn(m,1)\n",
    "\n",
    "xb = np.c_[np.ones((m,1)), x]\n",
    "theta = np.linalg.inv(xb.T.dot(xb)).dot(xb.T).dot(y)\n",
    "xnew = np.array([[0],[2]])\n",
    "xbnew = np.c_[np.ones((2,1)), xnew]\n",
    "ypredict = xbnew.dot(theta)\n",
    "\n",
    "plt.plot(xnew, ypredict, \"r-\")\n",
    "plt.plot(x, y ,'ro')\n",
    "plt.axis([0,2.0,0, 15.0])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.title(r'Random numbers ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge and Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#creating data with random noise\n",
    "x=np.arange(50)\n",
    "\n",
    "delta=np.random.uniform(-2.5,2.5, size=(50))\n",
    "np.random.shuffle(delta)\n",
    "y =0.5*x+5+delta\n",
    "\n",
    "#arranging data into 2x50 matrix\n",
    "a=np.array(x) #inputs\n",
    "b=np.array(y) #outputs\n",
    "\n",
    "#Split into training and test\n",
    "X_train=a[:37, np.newaxis]\n",
    "X_test=a[37:, np.newaxis]\n",
    "y_train=b[:37]\n",
    "y_test=b[37:]\n",
    "\n",
    "print (\"X_train: \", X_train.shape)\n",
    "print (\"y_train: \", y_train.shape)\n",
    "print (\"X_test: \", X_test.shape)\n",
    "print (\"y_test: \", y_test.shape)\n",
    "\n",
    "print (\"------------------------------------\")\n",
    "\n",
    "print (\"Ordinary Least Squares\")\n",
    "#Add Ordinary Least Squares fit\n",
    "reg=LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "pred=reg.predict(X_test)\n",
    "print (\"Prediction Shape: \", pred.shape)\n",
    "\n",
    "print('Coefficients: \\n', reg.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, pred))\n",
    "\n",
    "#plot\n",
    "plt.scatter(X_test,y_test,color='green', label=\"Training Data\")\n",
    "plt.plot(X_test, pred, color='black', label=\"Fit Line\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print (\"------------------------------------\")\n",
    "\n",
    "print (\"Ridge Regression\")\n",
    "\n",
    "ridge=linear_model.RidgeCV(alphas=[0.1,1.0,10.0])\n",
    "ridge.fit(X_train,y_train)\n",
    "print (\"Ridge Coefficient: \",ridge.coef_)\n",
    "print (\"Ridge Intercept: \", ridge.intercept_)\n",
    "#Look into graphing with Ridge fit\n",
    "\n",
    "print (\"------------------------------------\")\n",
    "\n",
    "print (\"Lasso\")\n",
    "lasso=linear_model.Lasso(alpha=0.1)\n",
    "lasso.fit(X_train,y_train)\n",
    "predl=lasso.predict(X_test)\n",
    "print(\"Lasso Coefficient: \", lasso.coef_)\n",
    "print(\"Lasso Intercept: \", lasso.intercept_)\n",
    "plt.scatter(X_test,y_test,color='green', label=\"Training Data\")\n",
    "plt.plot(X_test, predl, color='blue', label=\"Lasso\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The singular value decompostion\n",
    "How can we use the singular value decomposition to find the parameters $\\beta_j$? More details will come. We first note that a general $m\\times n$ matrix $\\hat{A}$ can be written in terms of a diagonal matrix $\\hat{\\Sigma}$ of dimensionality $n\\times n$ and two orthognal matrices $\\hat{U}$ and $\\hat{V}$, where the first has dimensionality $m \\times n$ and the last dimensionality $n\\times n$. We have then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{A} = \\hat{U}\\hat{\\Sigma}\\hat{V}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
